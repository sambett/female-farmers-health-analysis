{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 14:47:17,568 - INFO - Loading the dataset...\n",
      "2025-04-01 14:47:18,251 - INFO - Dataset loaded with 80 rows and 37 columns\n",
      "2025-04-01 14:47:18,252 - INFO - Preparing data for health analysis...\n",
      "2025-04-01 14:47:18,259 - INFO - Calculated BMI from height and weight\n",
      "2025-04-01 14:47:18,275 - INFO - Created BMI categories\n",
      "2025-04-01 14:47:18,277 - INFO - Created binary variable: is_smoker\n",
      "2025-04-01 14:47:18,280 - INFO - Created binary variable: exposed_to_tabouna\n",
      "2025-04-01 14:47:18,283 - INFO - Created binary variable: uses_neffa\n",
      "2025-04-01 14:47:18,288 - INFO - Created age group categories\n",
      "2025-04-01 14:47:18,292 - INFO - Calculated weekly work hours\n",
      "2025-04-01 14:47:18,296 - INFO - Created work intensity categories\n",
      "2025-04-01 14:47:18,307 - INFO - Analyzing BMI and health relationships...\n",
      "2025-04-01 14:47:18,310 - INFO -   Analyzing BMI vs. blood pressure\n",
      "2025-04-01 14:47:18,342 - INFO -     Saved blood pressure correlations to results/health_analysis\\bmi_analysis\\bmi_bp_correlations.csv\n",
      "2025-04-01 14:47:23,273 - INFO -     Saved BMI vs Systolic BP visualization to results/health_analysis\\bmi_analysis\\bmi_vs_TAS.png\n",
      "2025-04-01 14:47:24,271 - INFO -     Saved BMI vs Diastolic BP visualization to results/health_analysis\\bmi_analysis\\bmi_vs_TAD.png\n",
      "2025-04-01 14:47:24,273 - INFO -   Analyzing BMI by Age_Group\n",
      "2025-04-01 14:47:25,457 - INFO -     Saved BMI by Age_Group visualization to results/health_analysis\\bmi_analysis\\bmi_by_Age_Group.png\n",
      "2025-04-01 14:47:25,458 - INFO -   Analyzing BMI by Statut\n",
      "2025-04-01 14:47:26,087 - INFO -     Saved BMI by Statut visualization to results/health_analysis\\bmi_analysis\\bmi_by_Statut.png\n",
      "2025-04-01 14:47:26,088 - INFO -   Analyzing BMI by Situation maritale\n",
      "2025-04-01 14:47:26,856 - INFO -     Saved BMI by Situation maritale visualization to results/health_analysis\\bmi_analysis\\bmi_by_Situation_maritale.png\n",
      "2025-04-01 14:47:26,856 - INFO -   Analyzing BMI by Niveau socio-économique\n",
      "2025-04-01 14:47:27,585 - INFO -     Saved BMI by Niveau socio-économique visualization to results/health_analysis\\bmi_analysis\\bmi_by_Niveau_socio-économique.png\n",
      "2025-04-01 14:47:27,587 - INFO - Analyzing blood pressure relationships...\n",
      "2025-04-01 14:47:27,589 - INFO -   Analyzing blood pressure vs. age\n",
      "2025-04-01 14:47:28,409 - INFO -     Saved Age vs Systolic BP visualization to results/health_analysis\\blood_pressure\\age_vs_TAS.png\n",
      "2025-04-01 14:47:29,249 - INFO -     Saved Age vs Diastolic BP visualization to results/health_analysis\\blood_pressure\\age_vs_TAD.png\n",
      "2025-04-01 14:47:29,251 - INFO -   Analyzing blood pressure by Age_Group\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:30,139 - INFO -     Saved Systolic BP by Age_Group visualization to results/health_analysis\\blood_pressure\\TAS_by_Age_Group.png\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:31,418 - INFO -     Saved Diastolic BP by Age_Group visualization to results/health_analysis\\blood_pressure\\TAD_by_Age_Group.png\n",
      "2025-04-01 14:47:31,420 - INFO -   Analyzing blood pressure by BMI_Category\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:32,192 - INFO -     Saved Systolic BP by BMI_Category visualization to results/health_analysis\\blood_pressure\\TAS_by_BMI_Category.png\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:32,831 - INFO -     Saved Diastolic BP by BMI_Category visualization to results/health_analysis\\blood_pressure\\TAD_by_BMI_Category.png\n",
      "2025-04-01 14:47:32,832 - INFO -   Analyzing blood pressure by Statut\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:33,687 - INFO -     Saved Systolic BP by Statut visualization to results/health_analysis\\blood_pressure\\TAS_by_Statut.png\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:34,581 - INFO -     Saved Diastolic BP by Statut visualization to results/health_analysis\\blood_pressure\\TAD_by_Statut.png\n",
      "2025-04-01 14:47:34,583 - INFO -   Analyzing blood pressure by Work_Intensity\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:35,540 - INFO -     Saved Systolic BP by Work_Intensity visualization to results/health_analysis\\blood_pressure\\TAS_by_Work_Intensity.png\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:36,559 - INFO -     Saved Diastolic BP by Work_Intensity visualization to results/health_analysis\\blood_pressure\\TAD_by_Work_Intensity.png\n",
      "2025-04-01 14:47:36,560 - INFO -   Analyzing blood pressure by exposed_to_tabouna\n",
      "2025-04-01 14:47:36,584 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-04-01 14:47:36,597 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-04-01 14:47:36,635 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-04-01 14:47:36,641 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:37,262 - INFO -     Saved Systolic BP by exposed_to_tabouna visualization to results/health_analysis\\blood_pressure\\TAS_by_exposed_to_tabouna.png\n",
      "2025-04-01 14:47:37,279 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-04-01 14:47:37,287 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-04-01 14:47:37,322 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "2025-04-01 14:47:37,330 - INFO - Using categorical units to plot a list of strings that are all parsable as floats or dates. If these strings should be plotted as numbers, cast to the appropriate data type before plotting.\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:398: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
      "C:\\Users\\SelmaB\\AppData\\Local\\Temp\\ipykernel_49488\\843467922.py:439: DeprecationWarning: is_categorical_dtype is deprecated and will be removed in a future version. Use isinstance(dtype, pd.CategoricalDtype) instead\n",
      "  if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
      "2025-04-01 14:47:37,899 - INFO -     Saved Diastolic BP by exposed_to_tabouna visualization to results/health_analysis\\blood_pressure\\TAD_by_exposed_to_tabouna.png\n",
      "2025-04-01 14:47:37,901 - INFO -   Analyzing blood pressure vs. work hours\n",
      "2025-04-01 14:47:39,088 - INFO -     Saved Work Hours vs Systolic BP visualization to results/health_analysis\\blood_pressure\\hours_vs_TAS.png\n",
      "2025-04-01 14:47:39,977 - INFO -     Saved Work Hours vs Diastolic BP visualization to results/health_analysis\\blood_pressure\\hours_vs_TAD.png\n",
      "2025-04-01 14:47:39,979 - INFO - Analyzing traditional practices and health...\n",
      "2025-04-01 14:47:39,985 - INFO - Analyzing work patterns and health...\n",
      "2025-04-01 14:47:39,989 - INFO -   Analyzing health complaints by work intensity\n",
      "2025-04-01 14:47:39,991 - INFO -   Analyzing hours worked vs. health metrics\n",
      "2025-04-01 14:47:40,995 - INFO -     Saved Hours vs BMI visualization to results/health_analysis\\work_patterns\\hours_vs_BMI.png\n",
      "2025-04-01 14:47:41,907 - INFO -     Saved Hours vs TAS visualization to results/health_analysis\\work_patterns\\hours_vs_TAS.png\n",
      "2025-04-01 14:47:42,756 - INFO -     Saved Hours vs TAD visualization to results/health_analysis\\work_patterns\\hours_vs_TAD.png\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Health Outcomes Analysis for Female Farmers\n",
    "This script explores relationships between various factors and health outcomes\n",
    "in the female farmers dataset, focusing on aspects beyond protection equipment usage.\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: April 2, 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "from scipy import stats\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create output directory for results\n",
    "output_dir = 'results/health_analysis'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the preprocessed dataset\"\"\"\n",
    "    logger.info(\"Loading the dataset...\")\n",
    "    data = pd.read_excel('fixed_female_farmers_data.xlsx')\n",
    "    logger.info(f\"Dataset loaded with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "    return data\n",
    "\n",
    "def prepare_data_for_analysis(data):\n",
    "    \"\"\"\n",
    "    Prepare data for health analysis, including:\n",
    "    - Create derived health variables\n",
    "    - Format categorical variables\n",
    "    - Handle missing values\n",
    "    \"\"\"\n",
    "    logger.info(\"Preparing data for health analysis...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Create binary indicators for each health complaint category\n",
    "    health_categories = [\n",
    "        'Troubles cardio-respiratoires', \n",
    "        'Troubles cognitifs',\n",
    "        'Troubles neurologiques', \n",
    "        'Troubles cutanés/phanères'\n",
    "    ]\n",
    "    \n",
    "    # Filter to those that exist in the data\n",
    "    available_categories = [cat for cat in health_categories if cat in df.columns]\n",
    "    \n",
    "    # Create binary indicators\n",
    "    for category in available_categories:\n",
    "        binary_var = f\"has_{category.lower().replace('-', '_').replace(' ', '_').replace('/', '_')}\"\n",
    "        df[binary_var] = df[category].notna().astype(int)\n",
    "        logger.info(f\"Created binary variable: {binary_var}\")\n",
    "    \n",
    "    # Create a variable for any health complaint\n",
    "    if available_categories:\n",
    "        df['has_any_health_complaint'] = df[available_categories].notna().any(axis=1).astype(int)\n",
    "        logger.info(\"Created 'has_any_health_complaint' variable\")\n",
    "    \n",
    "    # Create BMI variable if height and weight are available\n",
    "    if all(var in df.columns for var in ['Poids', 'Taille']):\n",
    "        if 'BMI' not in df.columns:\n",
    "            df['BMI'] = df['Poids'] / ((df['Taille']/100) ** 2)\n",
    "            logger.info(\"Calculated BMI from height and weight\")\n",
    "            \n",
    "            # Create BMI categories\n",
    "            df['BMI_Category'] = pd.cut(\n",
    "                df['BMI'], \n",
    "                bins=[0, 18.5, 25, 30, 100],\n",
    "                labels=['Underweight', 'Normal', 'Overweight', 'Obese']\n",
    "            )\n",
    "            logger.info(\"Created BMI categories\")\n",
    "    \n",
    "    # Create binary variables for key exposures\n",
    "    exposure_vars = {\n",
    "        'Tabagisme': 'is_smoker',\n",
    "        'Fumées de Tabouna': 'exposed_to_tabouna',\n",
    "        'Neffa': 'uses_neffa'\n",
    "    }\n",
    "    \n",
    "    for var, new_var in exposure_vars.items():\n",
    "        if var in df.columns:\n",
    "            df[new_var] = (df[var] == 'oui').astype(int)\n",
    "            logger.info(f\"Created binary variable: {new_var}\")\n",
    "    \n",
    "    # Create age groups if not already present\n",
    "    if 'Age' in df.columns and 'Age_Group' not in df.columns:\n",
    "        df['Age_Group'] = pd.cut(\n",
    "            df['Age'], \n",
    "            bins=[0, 30, 40, 50, 60, 100],\n",
    "            labels=['<30', '30-40', '40-50', '50-60', '>60']\n",
    "        )\n",
    "        logger.info(\"Created age group categories\")\n",
    "    \n",
    "    # Create work intensity variable (hours per week)\n",
    "    if all(var in df.columns for var in ['H travail / jour', 'J travail / Sem']):\n",
    "        df['Hours_Per_Week'] = df['H travail / jour'] * df['J travail / Sem']\n",
    "        logger.info(\"Calculated weekly work hours\")\n",
    "        \n",
    "        # Create work intensity categories\n",
    "        df['Work_Intensity'] = pd.cut(\n",
    "            df['Hours_Per_Week'],\n",
    "            bins=[0, 30, 40, 50, 100],\n",
    "            labels=['Part-time', 'Regular', 'Intensive', 'Very Intensive']\n",
    "        )\n",
    "        logger.info(\"Created work intensity categories\")\n",
    "    \n",
    "    # Convert important categorical variables to proper categorical type\n",
    "    categorical_vars = [\n",
    "        'BMI_Category', 'Age_Group', 'Work_Intensity', \n",
    "        'Statut', 'Situation maritale', 'Niveau socio-économique'\n",
    "    ]\n",
    "    \n",
    "    for var in categorical_vars:\n",
    "        if var in df.columns:\n",
    "            df[var] = df[var].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def bmi_health_analysis(data):\n",
    "    \"\"\"Analyze relationships between BMI and health outcomes\"\"\"\n",
    "    logger.info(\"Analyzing BMI and health relationships...\")\n",
    "    \n",
    "    if 'BMI' not in data.columns or 'BMI_Category' not in data.columns:\n",
    "        logger.warning(\"BMI data not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for BMI analysis\n",
    "    bmi_dir = os.path.join(output_dir, \"bmi_analysis\")\n",
    "    os.makedirs(bmi_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Analyze relationship between BMI categories and health complaints\n",
    "    binary_health_vars = [col for col in data.columns if col.startswith('has_')]\n",
    "    \n",
    "    # Store chi-square results\n",
    "    chi_square_results = []\n",
    "    \n",
    "    for health_var in binary_health_vars:\n",
    "        logger.info(f\"  Testing BMI_Category vs {health_var}\")\n",
    "        \n",
    "        # Create contingency table\n",
    "        contingency = pd.crosstab(data['BMI_Category'], data[health_var])\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "            # Perform chi-square test\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "            \n",
    "            chi_square_results.append({\n",
    "                'Health_Variable': health_var,\n",
    "                'Chi_Square': chi2,\n",
    "                'P_value': p,\n",
    "                'DoF': dof,\n",
    "                'Significant': p < 0.05\n",
    "            })\n",
    "            \n",
    "            # Create visualization if significant\n",
    "            if p < 0.05:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                # Calculate percentages for each BMI category\n",
    "                props = pd.crosstab(\n",
    "                    data['BMI_Category'], \n",
    "                    data[health_var],\n",
    "                    normalize='index'\n",
    "                ) * 100\n",
    "                \n",
    "                # Create bar chart\n",
    "                props.plot(kind='bar', stacked=True)\n",
    "                \n",
    "                plt.title(f'Relationship between BMI and {health_var} (p={p:.4f})', fontsize=14)\n",
    "                plt.xlabel('BMI Category', fontsize=12)\n",
    "                plt.ylabel('Percentage', fontsize=12)\n",
    "                plt.legend(title='Has Condition', labels=['No', 'Yes'])\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save figure\n",
    "                fig_path = os.path.join(bmi_dir, f\"bmi_vs_{health_var}.png\")\n",
    "                plt.savefig(fig_path, dpi=300)\n",
    "                plt.close()\n",
    "                logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "    \n",
    "    # Save chi-square results\n",
    "    if chi_square_results:\n",
    "        chi_results_df = pd.DataFrame(chi_square_results)\n",
    "        chi_results_path = os.path.join(bmi_dir, \"bmi_health_chi_square.csv\")\n",
    "        chi_results_df.to_csv(chi_results_path, index=False)\n",
    "        logger.info(f\"Saved BMI chi-square results to {chi_results_path}\")\n",
    "    \n",
    "    # 2. Analyze relationship between continuous BMI and blood pressure\n",
    "    if all(var in data.columns for var in ['BMI', 'TAS', 'TAD']):\n",
    "        logger.info(\"  Analyzing BMI vs. blood pressure\")\n",
    "        \n",
    "        # Calculate correlations\n",
    "        corr_tas = stats.pearsonr(data['BMI'], data['TAS'])\n",
    "        corr_tad = stats.pearsonr(data['BMI'], data['TAD'])\n",
    "        \n",
    "        correlations = pd.DataFrame({\n",
    "            'Variable': ['Systolic BP', 'Diastolic BP'],\n",
    "            'Correlation': [corr_tas[0], corr_tad[0]],\n",
    "            'P_value': [corr_tas[1], corr_tad[1]],\n",
    "            'Significant': [corr_tas[1] < 0.05, corr_tad[1] < 0.05]\n",
    "        })\n",
    "        \n",
    "        # Save correlations\n",
    "        corr_path = os.path.join(bmi_dir, \"bmi_bp_correlations.csv\")\n",
    "        correlations.to_csv(corr_path, index=False)\n",
    "        logger.info(f\"    Saved blood pressure correlations to {corr_path}\")\n",
    "        \n",
    "        # Create visualizations\n",
    "        for bp_var, bp_name in [('TAS', 'Systolic'), ('TAD', 'Diastolic')]:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Create scatter plot with regression line\n",
    "            sns.regplot(\n",
    "                x='BMI', \n",
    "                y=bp_var, \n",
    "                data=data,\n",
    "                scatter_kws={'alpha': 0.6},\n",
    "                line_kws={'color': 'red'}\n",
    "            )\n",
    "            \n",
    "            # Get correlation and p-value\n",
    "            corr, p = stats.pearsonr(data['BMI'], data[bp_var])\n",
    "            \n",
    "            # Add correlation text\n",
    "            plt.annotate(\n",
    "                f'r = {corr:.2f}, p = {p:.4f}',\n",
    "                xy=(0.05, 0.95),\n",
    "                xycoords='axes fraction',\n",
    "                ha='left',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "            \n",
    "            plt.title(f'Relationship between BMI and {bp_name} Blood Pressure', fontsize=14)\n",
    "            plt.xlabel('BMI (kg/m²)', fontsize=12)\n",
    "            plt.ylabel(f'{bp_name} Blood Pressure (mmHg)', fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(bmi_dir, f\"bmi_vs_{bp_var}.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved BMI vs {bp_name} BP visualization to {fig_path}\")\n",
    "    \n",
    "    # 3. Compare BMI across different demographic groups\n",
    "    for group_var in ['Age_Group', 'Statut', 'Situation maritale', 'Niveau socio-économique']:\n",
    "        if group_var in data.columns:\n",
    "            logger.info(f\"  Analyzing BMI by {group_var}\")\n",
    "            \n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Create boxplot\n",
    "            sns.boxplot(x=group_var, y='BMI', data=data)\n",
    "            \n",
    "            # Add individual points\n",
    "            sns.stripplot(\n",
    "                x=group_var, \n",
    "                y='BMI', \n",
    "                data=data,\n",
    "                color='black',\n",
    "                alpha=0.3,\n",
    "                jitter=True\n",
    "            )\n",
    "            \n",
    "            # Perform ANOVA\n",
    "            groups = []\n",
    "            for category in data[group_var].cat.categories:\n",
    "                group_data = data[data[group_var] == category]['BMI'].dropna()\n",
    "                if len(group_data) > 0:\n",
    "                    groups.append(group_data)\n",
    "            \n",
    "            if len(groups) >= 2:\n",
    "                f_stat, p_value = stats.f_oneway(*groups)\n",
    "                \n",
    "                # Add ANOVA result\n",
    "                plt.annotate(\n",
    "                    f'ANOVA: F={f_stat:.2f}, p={p_value:.4f}',\n",
    "                    xy=(0.5, 0.97),\n",
    "                    xycoords='axes fraction',\n",
    "                    ha='center',\n",
    "                    va='top',\n",
    "                    bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "                )\n",
    "            \n",
    "            plt.title(f'BMI Distribution by {group_var}', fontsize=14)\n",
    "            plt.xlabel(group_var, fontsize=12)\n",
    "            plt.ylabel('BMI (kg/m²)', fontsize=12)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            if len(data[group_var].cat.categories) > 3:\n",
    "                plt.xticks(rotation=45, ha='right')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(bmi_dir, f\"bmi_by_{group_var.replace(' ', '_')}.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved BMI by {group_var} visualization to {fig_path}\")\n",
    "\n",
    "def blood_pressure_analysis(data):\n",
    "    \"\"\"Analyze factors affecting blood pressure\"\"\"\n",
    "    logger.info(\"Analyzing blood pressure relationships...\")\n",
    "    \n",
    "    bp_vars = ['TAS', 'TAD']\n",
    "    if not all(var in data.columns for var in bp_vars):\n",
    "        logger.warning(\"Blood pressure data not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for BP analysis\n",
    "    bp_dir = os.path.join(output_dir, \"blood_pressure\")\n",
    "    os.makedirs(bp_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Analyze relationship between blood pressure and age\n",
    "    if 'Age' in data.columns:\n",
    "        logger.info(\"  Analyzing blood pressure vs. age\")\n",
    "        \n",
    "        for bp_var, bp_name in [('TAS', 'Systolic'), ('TAD', 'Diastolic')]:\n",
    "            # Calculate correlation\n",
    "            corr, p = stats.pearsonr(data['Age'], data[bp_var])\n",
    "            \n",
    "            # Create scatter plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            sns.regplot(\n",
    "                x='Age',\n",
    "                y=bp_var,\n",
    "                data=data,\n",
    "                scatter_kws={'alpha': 0.6},\n",
    "                line_kws={'color': 'red'}\n",
    "            )\n",
    "            \n",
    "            # Add correlation text\n",
    "            plt.annotate(\n",
    "                f'r = {corr:.2f}, p = {p:.4f}',\n",
    "                xy=(0.05, 0.95),\n",
    "                xycoords='axes fraction',\n",
    "                ha='left',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "            \n",
    "            plt.title(f'Relationship between Age and {bp_name} Blood Pressure', fontsize=14)\n",
    "            plt.xlabel('Age (years)', fontsize=12)\n",
    "            plt.ylabel(f'{bp_name} Blood Pressure (mmHg)', fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(bp_dir, f\"age_vs_{bp_var}.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved Age vs {bp_name} BP visualization to {fig_path}\")\n",
    "    \n",
    "    # 2. Analyze blood pressure by different categorical factors\n",
    "    for group_var in ['Age_Group', 'BMI_Category', 'Statut', 'Work_Intensity', 'exposed_to_tabouna']:\n",
    "        if group_var in data.columns:\n",
    "            logger.info(f\"  Analyzing blood pressure by {group_var}\")\n",
    "            \n",
    "            for bp_var, bp_name in [('TAS', 'Systolic'), ('TAD', 'Diastolic')]:\n",
    "                plt.figure(figsize=(12, 6))\n",
    "                \n",
    "                # Create boxplot\n",
    "                sns.boxplot(x=group_var, y=bp_var, data=data)\n",
    "                \n",
    "                # Add individual points\n",
    "                sns.stripplot(\n",
    "                    x=group_var, \n",
    "                    y=bp_var, \n",
    "                    data=data,\n",
    "                    color='black',\n",
    "                    alpha=0.3,\n",
    "                    jitter=True\n",
    "                )\n",
    "                \n",
    "                # Perform ANOVA if the group variable is categorical\n",
    "                if pd.api.types.is_categorical_dtype(data[group_var]) or group_var in ['exposed_to_tabouna']:\n",
    "                    # For binary variables, use t-test instead\n",
    "                    if group_var == 'exposed_to_tabouna' or len(data[group_var].unique()) == 2:\n",
    "                        group0 = data[data[group_var] == 0][bp_var].dropna()\n",
    "                        group1 = data[data[group_var] == 1][bp_var].dropna()\n",
    "                        \n",
    "                        if len(group0) > 0 and len(group1) > 0:\n",
    "                            t_stat, p_value = stats.ttest_ind(group0, group1, equal_var=False)\n",
    "                            \n",
    "                            plt.annotate(\n",
    "                                f't-test: t={t_stat:.2f}, p={p_value:.4f}',\n",
    "                                xy=(0.5, 0.97),\n",
    "                                xycoords='axes fraction',\n",
    "                                ha='center',\n",
    "                                va='top',\n",
    "                                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "                            )\n",
    "                    else:\n",
    "                        groups = []\n",
    "                        for category in data[group_var].unique():\n",
    "                            group_data = data[data[group_var] == category][bp_var].dropna()\n",
    "                            if len(group_data) > 0:\n",
    "                                groups.append(group_data)\n",
    "                        \n",
    "                        if len(groups) >= 2:\n",
    "                            f_stat, p_value = stats.f_oneway(*groups)\n",
    "                            \n",
    "                            plt.annotate(\n",
    "                                f'ANOVA: F={f_stat:.2f}, p={p_value:.4f}',\n",
    "                                xy=(0.5, 0.97),\n",
    "                                xycoords='axes fraction',\n",
    "                                ha='center',\n",
    "                                va='top',\n",
    "                                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "                            )\n",
    "                \n",
    "                plt.title(f'{bp_name} Blood Pressure by {group_var}', fontsize=14)\n",
    "                plt.xlabel(group_var, fontsize=12)\n",
    "                plt.ylabel(f'{bp_name} Blood Pressure (mmHg)', fontsize=12)\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                \n",
    "                if pd.api.types.is_categorical_dtype(data[group_var]) and len(data[group_var].cat.categories) > 3:\n",
    "                    plt.xticks(rotation=45, ha='right')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save figure\n",
    "                fig_path = os.path.join(bp_dir, f\"{bp_var}_by_{group_var.replace(' ', '_')}.png\")\n",
    "                plt.savefig(fig_path, dpi=300)\n",
    "                plt.close()\n",
    "                logger.info(f\"    Saved {bp_name} BP by {group_var} visualization to {fig_path}\")\n",
    "    \n",
    "    # 3. Analyze the relationship between work hours and blood pressure\n",
    "    if 'Hours_Per_Week' in data.columns:\n",
    "        logger.info(\"  Analyzing blood pressure vs. work hours\")\n",
    "        \n",
    "        for bp_var, bp_name in [('TAS', 'Systolic'), ('TAD', 'Diastolic')]:\n",
    "            # Calculate correlation\n",
    "            corr, p = stats.pearsonr(data['Hours_Per_Week'], data[bp_var])\n",
    "            \n",
    "            # Create scatter plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            sns.regplot(\n",
    "                x='Hours_Per_Week',\n",
    "                y=bp_var,\n",
    "                data=data,\n",
    "                scatter_kws={'alpha': 0.6},\n",
    "                line_kws={'color': 'red'}\n",
    "            )\n",
    "            \n",
    "            # Add correlation text\n",
    "            plt.annotate(\n",
    "                f'r = {corr:.2f}, p = {p:.4f}',\n",
    "                xy=(0.05, 0.95),\n",
    "                xycoords='axes fraction',\n",
    "                ha='left',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "            \n",
    "            plt.title(f'Relationship between Work Hours and {bp_name} Blood Pressure', fontsize=14)\n",
    "            plt.xlabel('Hours Worked Per Week', fontsize=12)\n",
    "            plt.ylabel(f'{bp_name} Blood Pressure (mmHg)', fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(bp_dir, f\"hours_vs_{bp_var}.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved Work Hours vs {bp_name} BP visualization to {fig_path}\")\n",
    "\n",
    "def traditional_practices_analysis(data):\n",
    "    \"\"\"Analyze the impact of traditional practices on health\"\"\"\n",
    "    logger.info(\"Analyzing traditional practices and health...\")\n",
    "    \n",
    "    # Check if we have traditional practice data\n",
    "    if 'exposed_to_tabouna' not in data.columns:\n",
    "        logger.warning(\"Traditional practices data not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for traditional practices analysis\n",
    "    trad_dir = os.path.join(output_dir, \"traditional_practices\")\n",
    "    os.makedirs(trad_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Analyze relationship between Tabouna exposure and respiratory issues\n",
    "    if 'has_troubles_cardio_respiratoires' in data.columns:\n",
    "        logger.info(\"  Analyzing Tabouna exposure vs. respiratory issues\")\n",
    "        \n",
    "        # Create contingency table\n",
    "        contingency = pd.crosstab(\n",
    "            data['exposed_to_tabouna'], \n",
    "            data['has_troubles_cardio_respiratoires']\n",
    "        )\n",
    "        \n",
    "        # Perform chi-square test\n",
    "        chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "        \n",
    "        # Calculate risk ratio\n",
    "        risk_exposed = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "        risk_unexposed = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "        risk_ratio = risk_exposed / risk_unexposed\n",
    "        \n",
    "        # Create results dataframe\n",
    "        results = pd.DataFrame({\n",
    "            'Test': ['Tabouna exposure vs. Respiratory issues'],\n",
    "            'Chi_Square': [chi2],\n",
    "            'P_value': [p],\n",
    "            'Risk_Ratio': [risk_ratio],\n",
    "            'Risk_Exposed': [risk_exposed],\n",
    "            'Risk_Unexposed': [risk_unexposed],\n",
    "            'Significant': [p < 0.05]\n",
    "        })\n",
    "        \n",
    "        # Save results\n",
    "        results_path = os.path.join(trad_dir, \"tabouna_respiratory_results.csv\")\n",
    "        results.to_csv(results_path, index=False)\n",
    "        logger.info(f\"    Saved results to {results_path}\")\n",
    "        \n",
    "        # Create visualization\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Calculate percentages\n",
    "        props = pd.crosstab(\n",
    "            data['exposed_to_tabouna'], \n",
    "            data['has_troubles_cardio_respiratoires'],\n",
    "            normalize='index'\n",
    "        ) * 100\n",
    "        \n",
    "        # Create bar chart\n",
    "        ax = props[1].plot(kind='bar')\n",
    "        \n",
    "        plt.title(f'Respiratory Issues by Tabouna Exposure (p={p:.4f}, RR={risk_ratio:.2f})', fontsize=14)\n",
    "        plt.xlabel('Exposed to Tabouna Smoke', fontsize=12)\n",
    "        plt.ylabel('Percentage with Respiratory Issues', fontsize=12)\n",
    "        plt.xticks([0, 1], ['No', 'Yes'])\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, v in enumerate(props[1]):\n",
    "            ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(trad_dir, \"tabouna_respiratory_issues.png\")\n",
    "        plt.savefig(fig_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "    \n",
    "    # 2. Analyze Tabouna exposure and other health complaints\n",
    "    other_health_vars = [var for var in data.columns if var.startswith('has_') and var != 'has_troubles_cardio_respiratoires']\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for health_var in other_health_vars:\n",
    "        # Create contingency table\n",
    "        contingency = pd.crosstab(data['exposed_to_tabouna'], data[health_var])\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "            # Perform chi-square test\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "            \n",
    "            # Calculate risk ratio if possible\n",
    "            if 1 in contingency.index and 0 in contingency.index and 1 in contingency.columns:\n",
    "                risk_exposed = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "                risk_unexposed = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "                risk_ratio = risk_exposed / risk_unexposed\n",
    "            else:\n",
    "                risk_ratio = np.nan\n",
    "            \n",
    "            results.append({\n",
    "                'Health_Outcome': health_var,\n",
    "                'Chi_Square': chi2,\n",
    "                'P_value': p,\n",
    "                'Risk_Ratio': risk_ratio,\n",
    "                'Significant': p < 0.05\n",
    "            })\n",
    "    \n",
    "    # Save all results\n",
    "    if results:\n",
    "        all_results_df = pd.DataFrame(results)\n",
    "        all_results_path = os.path.join(trad_dir, \"tabouna_all_health_outcomes.csv\")\n",
    "        all_results_df.to_csv(all_results_path, index=False)\n",
    "        logger.info(f\"  Saved all Tabouna health outcomes to {all_results_path}\")\n",
    "\n",
    "def work_patterns_analysis(data):\n",
    "    \"\"\"Analyze relationships between work patterns and health\"\"\"\n",
    "    logger.info(\"Analyzing work patterns and health...\")\n",
    "    \n",
    "    # Check if we have work pattern data\n",
    "    work_vars = ['H travail / jour', 'J travail / Sem', 'Hours_Per_Week', 'Work_Intensity']\n",
    "    if not any(var in data.columns for var in work_vars):\n",
    "        logger.warning(\"Work pattern data not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for work pattern analysis\n",
    "    work_dir = os.path.join(output_dir, \"work_patterns\")\n",
    "    os.makedirs(work_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Analyze health complaints by work intensity\n",
    "    if 'Work_Intensity' in data.columns:\n",
    "        logger.info(\"  Analyzing health complaints by work intensity\")\n",
    "        \n",
    "        health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "        \n",
    "        for health_var in health_vars:\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(data['Work_Intensity'], data[health_var])\n",
    "            \n",
    "            # Check if we have enough data\n",
    "            if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "                # Perform chi-square test\n",
    "                chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "                \n",
    "                # Create visualization if significant\n",
    "                if p < 0.05:\n",
    "                    logger.info(f\"    Significant relationship: Work_Intensity vs {health_var} (p={p:.4f})\")\n",
    "                    \n",
    "                    plt.figure(figsize=(12, 6))\n",
    "                    \n",
    "                    # Calculate percentages\n",
    "                    props = pd.crosstab(\n",
    "                        data['Work_Intensity'], \n",
    "                        data[health_var],\n",
    "                        normalize='index'\n",
    "                    ) * 100\n",
    "                    \n",
    "                    # Create bar chart for the \"Yes\" column (health complaint present)\n",
    "                    ax = props[1].plot(kind='bar')\n",
    "                    \n",
    "                    plt.title(f'{health_var} by Work Intensity (p={p:.4f})', fontsize=14)\n",
    "                    plt.xlabel('Work Intensity', fontsize=12)\n",
    "                    plt.ylabel(f'Percentage with {health_var}', fontsize=12)\n",
    "                    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                    \n",
    "                    # Add percentage labels\n",
    "                    for i, v in enumerate(props[1]):\n",
    "                        ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # Save figure\n",
    "                    fig_path = os.path.join(work_dir, f\"work_intensity_vs_{health_var}.png\")\n",
    "                    plt.savefig(fig_path, dpi=300)\n",
    "                    plt.close()\n",
    "                    logger.info(f\"      Saved visualization to {fig_path}\")\n",
    "    \n",
    "    # 2. Analyze relationship between hours worked and health metrics\n",
    "    if 'Hours_Per_Week' in data.columns:\n",
    "        logger.info(\"  Analyzing hours worked vs. health metrics\")\n",
    "        \n",
    "        # Check if we have health metrics\n",
    "        health_metrics = ['BMI', 'TAS', 'TAD']\n",
    "        available_metrics = [var for var in health_metrics if var in data.columns]\n",
    "        \n",
    "        for metric in available_metrics:\n",
    "            # Calculate correlation\n",
    "            corr, p = stats.pearsonr(data['Hours_Per_Week'], data[metric])\n",
    "            \n",
    "            # Create scatter plot\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            sns.regplot(\n",
    "                x='Hours_Per_Week',\n",
    "                y=metric,\n",
    "                data=data,\n",
    "                scatter_kws={'alpha': 0.6},\n",
    "                line_kws={'color': 'red'}\n",
    "            )\n",
    "            \n",
    "            # Add correlation text\n",
    "            plt.annotate(\n",
    "                f'r = {corr:.2f}, p = {p:.4f}',\n",
    "                xy=(0.05, 0.95),\n",
    "                xycoords='axes fraction',\n",
    "                ha='left',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "            \n",
    "            plt.title(f'Relationship between Work Hours and {metric}', fontsize=14)\n",
    "            plt.xlabel('Hours Worked Per Week', fontsize=12)\n",
    "            plt.ylabel(metric, fontsize=12)\n",
    "            plt.grid(True, linestyle='--', alpha=0.7)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(work_dir, f\"hours_vs_{metric}.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved Hours vs {metric} visualization to {fig_path}\")\n",
    "\n",
    "# Optional: Add a main block to run the script\n",
    "if __name__ == \"__main__\":\n",
    "    data = load_data()\n",
    "    prepared_data = prepare_data_for_analysis(data)\n",
    "    bmi_health_analysis(prepared_data)\n",
    "    blood_pressure_analysis(prepared_data)\n",
    "    traditional_practices_analysis(prepared_data)\n",
    "    work_patterns_analysis(prepared_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Complete Missing Health Analyses for Female Farmers\n",
    "This script focuses on completing the missing analyses:\n",
    "1. Traditional practices analysis\n",
    "2. Transportation health analysis\n",
    "3. Experience health analysis\n",
    "4. Multivariate models\n",
    "5. Summary report\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: April 2, 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import glm\n",
    "from scipy import stats\n",
    "import os\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set output directory for results\n",
    "output_dir = 'C:/Users/SelmaB/Desktop/Project/Analysis/2.Anova part two all determinants/results/health_analysis'\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the preprocessed dataset\"\"\"\n",
    "    logger.info(\"Loading the dataset...\")\n",
    "    try:\n",
    "        data = pd.read_excel('C:/Users/SelmaB/Desktop/Project/Analysis/fixed_female_farmers_data.xlsx')\n",
    "        logger.info(f\"Dataset loaded with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "        return data\n",
    "    except Exception as e:\n",
    "        # Try alternative paths if the first one fails\n",
    "        try:\n",
    "            data = pd.read_excel('fixed_female_farmers_data.xlsx')\n",
    "            logger.info(f\"Dataset loaded with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "            return data\n",
    "        except Exception as e2:\n",
    "            logger.error(f\"Error loading data: {str(e2)}\")\n",
    "            raise\n",
    "\n",
    "def prepare_data_for_analysis(data):\n",
    "    \"\"\"\n",
    "    Prepare data for health analysis, including:\n",
    "    - Create derived health variables\n",
    "    - Format categorical variables\n",
    "    - Handle missing values\n",
    "    \"\"\"\n",
    "    logger.info(\"Preparing data for health analysis...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Create binary indicators for each health complaint category\n",
    "    health_categories = [\n",
    "        'Troubles cardio-respiratoires', \n",
    "        'Troubles cognitifs',\n",
    "        'Troubles neurologiques', \n",
    "        'Troubles cutanés/phanères'\n",
    "    ]\n",
    "    \n",
    "    # Filter to those that exist in the data\n",
    "    available_categories = [cat for cat in health_categories if cat in df.columns]\n",
    "    \n",
    "    # Create binary indicators\n",
    "    for category in available_categories:\n",
    "        binary_var = f\"has_{category.lower().replace('-', '_').replace(' ', '_').replace('/', '_')}\"\n",
    "        df[binary_var] = df[category].notna().astype(int)\n",
    "        logger.info(f\"Created binary variable: {binary_var}\")\n",
    "    \n",
    "    # Create a variable for any health complaint\n",
    "    if available_categories:\n",
    "        df['has_any_health_complaint'] = df[available_categories].notna().any(axis=1).astype(int)\n",
    "        logger.info(\"Created 'has_any_health_complaint' variable\")\n",
    "    \n",
    "    # Create BMI variable if height and weight are available\n",
    "    if all(var in df.columns for var in ['Poids', 'Taille']):\n",
    "        if 'BMI' not in df.columns:\n",
    "            df['BMI'] = df['Poids'] / ((df['Taille']/100) ** 2)\n",
    "            logger.info(\"Calculated BMI from height and weight\")\n",
    "            \n",
    "            # Create BMI categories\n",
    "            df['BMI_Category'] = pd.cut(\n",
    "                df['BMI'], \n",
    "                bins=[0, 18.5, 25, 30, 100],\n",
    "                labels=['Underweight', 'Normal', 'Overweight', 'Obese']\n",
    "            )\n",
    "            logger.info(\"Created BMI categories\")\n",
    "    \n",
    "    # Create binary variables for key exposures\n",
    "    exposure_vars = {\n",
    "        'Tabagisme': 'is_smoker',\n",
    "        'Fumées de Tabouna': 'exposed_to_tabouna',\n",
    "        'Neffa': 'uses_neffa'\n",
    "    }\n",
    "    \n",
    "    for var, new_var in exposure_vars.items():\n",
    "        if var in df.columns:\n",
    "            df[new_var] = (df[var] == 'oui').astype(int)\n",
    "            logger.info(f\"Created binary variable: {new_var}\")\n",
    "    \n",
    "    # Create age groups if not already present\n",
    "    if 'Age' in df.columns and 'Age_Group' not in df.columns:\n",
    "        df['Age_Group'] = pd.cut(\n",
    "            df['Age'], \n",
    "            bins=[0, 30, 40, 50, 60, 100],\n",
    "            labels=['<30', '30-40', '40-50', '50-60', '>60']\n",
    "        )\n",
    "        logger.info(\"Created age group categories\")\n",
    "    \n",
    "    # Create work intensity variable (hours per week)\n",
    "    if all(var in df.columns for var in ['H travail / jour', 'J travail / Sem']):\n",
    "        df['Hours_Per_Week'] = df['H travail / jour'] * df['J travail / Sem']\n",
    "        logger.info(\"Calculated weekly work hours\")\n",
    "        \n",
    "        # Create work intensity categories\n",
    "        df['Work_Intensity'] = pd.cut(\n",
    "            df['Hours_Per_Week'],\n",
    "            bins=[0, 30, 40, 50, 100],\n",
    "            labels=['Part-time', 'Regular', 'Intensive', 'Very Intensive']\n",
    "        )\n",
    "        logger.info(\"Created work intensity categories\")\n",
    "    \n",
    "    # Convert important categorical variables to proper categorical type\n",
    "    categorical_vars = [\n",
    "        'BMI_Category', 'Age_Group', 'Work_Intensity', \n",
    "        'Statut', 'Situation maritale', 'Niveau socio-économique'\n",
    "    ]\n",
    "    \n",
    "    for var in categorical_vars:\n",
    "        if var in df.columns:\n",
    "            df[var] = df[var].astype('category')\n",
    "    \n",
    "    return df\n",
    "\n",
    "def traditional_practices_analysis(data):\n",
    "    \"\"\"Analyze the impact of traditional practices on health\"\"\"\n",
    "    logger.info(\"Analyzing traditional practices and health...\")\n",
    "    \n",
    "    # Check if we have traditional practice data\n",
    "    if 'exposed_to_tabouna' not in data.columns and 'Fumées de Tabouna' in data.columns:\n",
    "        # Create the binary variable if it doesn't exist\n",
    "        data['exposed_to_tabouna'] = (data['Fumées de Tabouna'] == 'oui').astype(int)\n",
    "        logger.info(\"Created binary variable: exposed_to_tabouna\")\n",
    "    \n",
    "    if 'uses_neffa' not in data.columns and 'Neffa' in data.columns:\n",
    "        # Create the binary variable if it doesn't exist\n",
    "        data['uses_neffa'] = (data['Neffa'] == 'oui').astype(int)\n",
    "        logger.info(\"Created binary variable: uses_neffa\")\n",
    "        \n",
    "    if 'exposed_to_tabouna' not in data.columns and 'uses_neffa' not in data.columns:\n",
    "        logger.warning(\"Traditional practices data not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for traditional practices analysis\n",
    "    trad_dir = os.path.join(output_dir, \"traditional_practices\")\n",
    "    os.makedirs(trad_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Analyze relationship between Tabouna exposure and respiratory issues\n",
    "    if 'exposed_to_tabouna' in data.columns:\n",
    "        # Find respiratory issues variable\n",
    "        resp_vars = [col for col in data.columns if 'respir' in col.lower() or 'cardio' in col.lower()]\n",
    "        resp_vars.extend([col for col in data.columns if col.startswith('has_') and ('respir' in col.lower() or 'cardio' in col.lower())])\n",
    "        \n",
    "        resp_var = None\n",
    "        if 'has_troubles_cardio_respiratoires' in resp_vars:\n",
    "            resp_var = 'has_troubles_cardio_respiratoires'\n",
    "        elif resp_vars:\n",
    "            resp_var = resp_vars[0]\n",
    "        \n",
    "        if resp_var:\n",
    "            logger.info(f\"  Analyzing Tabouna exposure vs. {resp_var}\")\n",
    "            \n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(\n",
    "                data['exposed_to_tabouna'], \n",
    "                data[resp_var]\n",
    "            )\n",
    "            \n",
    "            # Perform chi-square test\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "            \n",
    "            # Calculate risk ratio if possible\n",
    "            if 1 in contingency.index and 0 in contingency.index and 1 in contingency.columns:\n",
    "                risk_exposed = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "                risk_unexposed = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "                risk_ratio = risk_exposed / risk_unexposed\n",
    "            else:\n",
    "                risk_exposed = np.nan\n",
    "                risk_unexposed = np.nan\n",
    "                risk_ratio = np.nan\n",
    "            \n",
    "            # Create results dataframe\n",
    "            results = pd.DataFrame({\n",
    "                'Test': ['Tabouna exposure vs. Respiratory issues'],\n",
    "                'Chi_Square': [chi2],\n",
    "                'P_value': [p],\n",
    "                'Risk_Ratio': [risk_ratio],\n",
    "                'Risk_Exposed': [risk_exposed],\n",
    "                'Risk_Unexposed': [risk_unexposed],\n",
    "                'Significant': [p < 0.05]\n",
    "            })\n",
    "            \n",
    "            # Save results\n",
    "            results_path = os.path.join(trad_dir, \"tabouna_respiratory_results.csv\")\n",
    "            results.to_csv(results_path, index=False)\n",
    "            logger.info(f\"    Saved results to {results_path}\")\n",
    "            \n",
    "            # Create visualization\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Calculate percentages\n",
    "            props = pd.crosstab(\n",
    "                data['exposed_to_tabouna'], \n",
    "                data[resp_var],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            \n",
    "            # Create bar chart\n",
    "            ax = props[1].plot(kind='bar')\n",
    "            \n",
    "            plt.title(f'Respiratory Issues by Tabouna Exposure (p={p:.4f}, RR={risk_ratio:.2f})', fontsize=14)\n",
    "            plt.xlabel('Exposed to Tabouna Smoke', fontsize=12)\n",
    "            plt.ylabel('Percentage with Respiratory Issues', fontsize=12)\n",
    "            plt.xticks([0, 1], ['No', 'Yes'])\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Add percentage labels\n",
    "            for i, v in enumerate(props[1]):\n",
    "                ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(trad_dir, \"tabouna_respiratory_issues.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "    \n",
    "    # 2. Analyze Neffa usage and health complaints\n",
    "    if 'uses_neffa' in data.columns:\n",
    "        logger.info(\"  Analyzing Neffa usage and health complaints\")\n",
    "        \n",
    "        health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for health_var in health_vars:\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(data['uses_neffa'], data[health_var])\n",
    "            \n",
    "            # Check if we have enough data\n",
    "            if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "                # Perform chi-square test\n",
    "                chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "                \n",
    "                # Calculate risk ratio if possible\n",
    "                if 1 in contingency.index and 0 in contingency.index and 1 in contingency.columns:\n",
    "                    risk_users = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "                    risk_nonusers = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "                    risk_ratio = risk_users / risk_nonusers\n",
    "                else:\n",
    "                    risk_ratio = np.nan\n",
    "                \n",
    "                results.append({\n",
    "                    'Health_Outcome': health_var,\n",
    "                    'Chi_Square': chi2,\n",
    "                    'P_value': p,\n",
    "                    'Risk_Ratio': risk_ratio,\n",
    "                    'Significant': p < 0.05\n",
    "                })\n",
    "        \n",
    "        # Save results\n",
    "        if results:\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_path = os.path.join(trad_dir, \"neffa_health_outcomes.csv\")\n",
    "            results_df.to_csv(results_path, index=False)\n",
    "            logger.info(f\"    Saved Neffa usage vs. health outcomes to {results_path}\")\n",
    "            \n",
    "            # Create visualizations for significant relationships\n",
    "            sig_results = results_df[results_df['Significant']]\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                health_var = row['Health_Outcome']\n",
    "                p = row['P_value']\n",
    "                rr = row['Risk_Ratio']\n",
    "                \n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                # Calculate percentages\n",
    "                props = pd.crosstab(\n",
    "                    data['uses_neffa'], \n",
    "                    data[health_var],\n",
    "                    normalize='index'\n",
    "                ) * 100\n",
    "                \n",
    "                # Create bar chart\n",
    "                ax = props[1].plot(kind='bar')\n",
    "                \n",
    "                plt.title(f'{health_var} by Neffa Usage (p={p:.4f}, RR={rr:.2f})', fontsize=14)\n",
    "                plt.xlabel('Uses Neffa', fontsize=12)\n",
    "                plt.ylabel(f'Percentage with {health_var}', fontsize=12)\n",
    "                plt.xticks([0, 1], ['No', 'Yes'])\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                \n",
    "                # Add percentage labels\n",
    "                for i, v in enumerate(props[1]):\n",
    "                    ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save figure\n",
    "                fig_path = os.path.join(trad_dir, f\"neffa_vs_{health_var}.png\")\n",
    "                plt.savefig(fig_path, dpi=300)\n",
    "                plt.close()\n",
    "                logger.info(f\"      Saved visualization to {fig_path}\")\n",
    "    \n",
    "    # 3. Create combined traditional practice score \n",
    "    if 'exposed_to_tabouna' in data.columns and 'uses_neffa' in data.columns:\n",
    "        logger.info(\"  Creating combined traditional practice exposure score\")\n",
    "        \n",
    "        # Create exposure score (0-2)\n",
    "        data['trad_exposure_score'] = data['exposed_to_tabouna'] + data['uses_neffa']\n",
    "        \n",
    "        # Analyze health outcomes by exposure score\n",
    "        health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "        \n",
    "        for health_var in health_vars:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Calculate percentages\n",
    "            props = pd.crosstab(\n",
    "                data['trad_exposure_score'], \n",
    "                data[health_var],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            \n",
    "            # Create bar chart\n",
    "            ax = props[1].plot(kind='bar')\n",
    "            \n",
    "            plt.title(f'{health_var} by Traditional Practice Exposure Score', fontsize=14)\n",
    "            plt.xlabel('Exposure Score (0=None, 1=One practice, 2=Both practices)', fontsize=12)\n",
    "            plt.ylabel(f'Percentage with {health_var}', fontsize=12)\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Add percentage labels\n",
    "            for i, v in enumerate(props[1]):\n",
    "                ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(trad_dir, f\"trad_exposure_score_vs_{health_var}.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved Traditional Practices Score vs {health_var} visualization\")\n",
    "\n",
    "def transportation_health_analysis(data):\n",
    "    \"\"\"Analyze relationship between transportation method and health\"\"\"\n",
    "    logger.info(\"Analyzing transportation method and health...\")\n",
    "    \n",
    "    if 'Moyen de transport' not in data.columns:\n",
    "        logger.warning(\"Transportation data not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for transportation analysis\n",
    "    trans_dir = os.path.join(output_dir, \"transportation\")\n",
    "    os.makedirs(trans_dir, exist_ok=True)\n",
    "    \n",
    "    # Create binary variable for walking (a pieds) vs. other transport\n",
    "    data['transport_walking'] = (data['Moyen de transport'] == 'a pieds').astype(int)\n",
    "    \n",
    "    # 1. Analyze relationship between walking and health complaints\n",
    "    health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for health_var in health_vars:\n",
    "        # Create contingency table\n",
    "        contingency = pd.crosstab(data['transport_walking'], data[health_var])\n",
    "        \n",
    "        # Check if we have enough data\n",
    "        if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "            # Perform chi-square test\n",
    "            chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "            \n",
    "            # Calculate risk ratio if possible\n",
    "            if 1 in contingency.index and 0 in contingency.index and 1 in contingency.columns:\n",
    "                risk_walking = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "                risk_other = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "                risk_ratio = risk_walking / risk_other\n",
    "            else:\n",
    "                risk_ratio = np.nan\n",
    "            \n",
    "            results.append({\n",
    "                'Health_Outcome': health_var,\n",
    "                'Chi_Square': chi2,\n",
    "                'P_value': p,\n",
    "                'Risk_Ratio': risk_ratio,\n",
    "                'Significant': p < 0.05\n",
    "            })\n",
    "    \n",
    "    # Save results\n",
    "    if results:\n",
    "        results_df = pd.DataFrame(results)\n",
    "        results_path = os.path.join(trans_dir, \"walking_health_results.csv\")\n",
    "        results_df.to_csv(results_path, index=False)\n",
    "        logger.info(f\"  Saved walking vs. health results to {results_path}\")\n",
    "        \n",
    "        # Create visualizations for significant relationships\n",
    "        sig_results = results_df[results_df['Significant']]\n",
    "        \n",
    "        for _, row in sig_results.iterrows():\n",
    "            health_var = row['Health_Outcome']\n",
    "            p = row['P_value']\n",
    "            rr = row['Risk_Ratio']\n",
    "            \n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Calculate percentages\n",
    "            props = pd.crosstab(\n",
    "                data['transport_walking'], \n",
    "                data[health_var],\n",
    "                normalize='index'\n",
    "            ) * 100\n",
    "            \n",
    "            # Create bar chart for the \"Yes\" column (health complaint present)\n",
    "            ax = props[1].plot(kind='bar')\n",
    "            \n",
    "            plt.title(f'{health_var} by Transportation Method (p={p:.4f}, RR={rr:.2f})', fontsize=14)\n",
    "            plt.xlabel('Walking as Transportation', fontsize=12)\n",
    "            plt.ylabel(f'Percentage with {health_var}', fontsize=12)\n",
    "            plt.xticks([0, 1], ['No', 'Yes'])\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            # Add percentage labels\n",
    "            for i, v in enumerate(props[1]):\n",
    "                ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(trans_dir, f\"walking_vs_{health_var}.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "    \n",
    "    # 2. Analyze relationship between transportation method and BMI\n",
    "    if 'BMI' in data.columns:\n",
    "        logger.info(\"  Analyzing transportation method vs. BMI\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create boxplot\n",
    "        sns.boxplot(x='transport_walking', y='BMI', data=data)\n",
    "        \n",
    "        # Add individual points\n",
    "        sns.stripplot(\n",
    "            x='transport_walking', \n",
    "            y='BMI', \n",
    "            data=data,\n",
    "            color='black',\n",
    "            alpha=0.3,\n",
    "            jitter=True\n",
    "        )\n",
    "        \n",
    "        # Perform t-test\n",
    "        walking_bmi = data[data['transport_walking'] == 1]['BMI'].dropna()\n",
    "        other_bmi = data[data['transport_walking'] == 0]['BMI'].dropna()\n",
    "        \n",
    "        if len(walking_bmi) > 0 and len(other_bmi) > 0:\n",
    "            t_stat, p_value = stats.ttest_ind(walking_bmi, other_bmi, equal_var=False)\n",
    "            \n",
    "            # Add t-test result\n",
    "            plt.annotate(\n",
    "                f't-test: t={t_stat:.2f}, p={p_value:.4f}',\n",
    "                xy=(0.5, 0.97),\n",
    "                xycoords='axes fraction',\n",
    "                ha='center',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "            \n",
    "            # Add means\n",
    "            mean_walking = walking_bmi.mean()\n",
    "            mean_other = other_bmi.mean()\n",
    "            \n",
    "            plt.annotate(\n",
    "                f'Walking mean: {mean_walking:.1f}\\nOther mean: {mean_other:.1f}',\n",
    "                xy=(0.5, 0.85),\n",
    "                xycoords='axes fraction',\n",
    "                ha='center',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "        \n",
    "        plt.title('BMI by Transportation Method', fontsize=14)\n",
    "        plt.xlabel('Walking as Transportation', fontsize=12)\n",
    "        plt.ylabel('BMI (kg/m²)', fontsize=12)\n",
    "        plt.xticks([0, 1], ['No', 'Yes'])\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(trans_dir, \"walking_vs_bmi.png\")\n",
    "        plt.savefig(fig_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "        \n",
    "    # 3. Analyze relationship between transportation method and blood pressure\n",
    "    if all(var in data.columns for var in ['TAS', 'TAD']):\n",
    "        logger.info(\"  Analyzing transportation method vs. blood pressure\")\n",
    "        \n",
    "        for bp_var, bp_name in [('TAS', 'Systolic'), ('TAD', 'Diastolic')]:\n",
    "            plt.figure(figsize=(10, 6))\n",
    "            \n",
    "            # Create boxplot\n",
    "            sns.boxplot(x='transport_walking', y=bp_var, data=data)\n",
    "            \n",
    "            # Add individual points\n",
    "            sns.stripplot(\n",
    "                x='transport_walking', \n",
    "                y=bp_var, \n",
    "                data=data,\n",
    "                color='black',\n",
    "                alpha=0.3,\n",
    "                jitter=True\n",
    "            )\n",
    "            \n",
    "            # Perform t-test\n",
    "            walking_bp = data[data['transport_walking'] == 1][bp_var].dropna()\n",
    "            other_bp = data[data['transport_walking'] == 0][bp_var].dropna()\n",
    "            \n",
    "            if len(walking_bp) > 0 and len(other_bp) > 0:\n",
    "                t_stat, p_value = stats.ttest_ind(walking_bp, other_bp, equal_var=False)\n",
    "                \n",
    "                # Add t-test result\n",
    "                plt.annotate(\n",
    "                    f't-test: t={t_stat:.2f}, p={p_value:.4f}',\n",
    "                    xy=(0.5, 0.97),\n",
    "                    xycoords='axes fraction',\n",
    "                    ha='center',\n",
    "                    va='top',\n",
    "                    bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "                )\n",
    "                \n",
    "                # Add means\n",
    "                mean_walking = walking_bp.mean()\n",
    "                mean_other = other_bp.mean()\n",
    "                \n",
    "                plt.annotate(\n",
    "                    f'Walking mean: {mean_walking:.1f}\\nOther mean: {mean_other:.1f}',\n",
    "                    xy=(0.5, 0.85),\n",
    "                    xycoords='axes fraction',\n",
    "                    ha='center',\n",
    "                    va='top',\n",
    "                    bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "                )\n",
    "            \n",
    "            plt.title(f'{bp_name} Blood Pressure by Transportation Method', fontsize=14)\n",
    "            plt.xlabel('Walking as Transportation', fontsize=12)\n",
    "            plt.ylabel(f'{bp_name} Blood Pressure (mmHg)', fontsize=12)\n",
    "            plt.xticks([0, 1], ['No', 'Yes'])\n",
    "            plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            \n",
    "            # Save figure\n",
    "            fig_path = os.path.join(trans_dir, f\"{bp_var}_by_transportation.png\")\n",
    "            plt.savefig(fig_path, dpi=300)\n",
    "            plt.close()\n",
    "            logger.info(f\"    Saved {bp_name} BP by transportation visualization to {fig_path}\")\n",
    "\n",
    "def experience_health_analysis(data):\n",
    "    \"\"\"Analyze relationship between agricultural experience and health\"\"\"\n",
    "    logger.info(\"Analyzing agricultural experience and health...\")\n",
    "    \n",
    "    if 'Ancienneté agricole' not in data.columns:\n",
    "        logger.warning(\"Agricultural experience data not available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for experience analysis\n",
    "    exp_dir = os.path.join(output_dir, \"experience\")\n",
    "    os.makedirs(exp_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Compare experience levels across health complaint groups\n",
    "    health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "    \n",
    "    for health_var in health_vars:\n",
    "        logger.info(f\"  Analyzing experience vs. {health_var}\")\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create boxplot\n",
    "        sns.boxplot(x=health_var, y='Ancienneté agricole', data=data)\n",
    "        \n",
    "        # Add individual points\n",
    "        sns.stripplot(\n",
    "            x=health_var, \n",
    "            y='Ancienneté agricole', \n",
    "            data=data,\n",
    "            color='black',\n",
    "            alpha=0.3,\n",
    "            jitter=True\n",
    "        )\n",
    "        \n",
    "        # Perform t-test\n",
    "        health_exp = data[data[health_var] == 1]['Ancienneté agricole'].dropna()\n",
    "        no_health_exp = data[data[health_var] == 0]['Ancienneté agricole'].dropna()\n",
    "        \n",
    "        if len(health_exp) > 0 and len(no_health_exp) > 0:\n",
    "            t_stat, p_value = stats.ttest_ind(health_exp, no_health_exp, equal_var=False)\n",
    "            \n",
    "            # Add t-test result\n",
    "            plt.annotate(\n",
    "                f't-test: t={t_stat:.2f}, p={p_value:.4f}',\n",
    "                xy=(0.5, 0.97),\n",
    "                xycoords='axes fraction',\n",
    "                ha='center',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "            \n",
    "            # Add means\n",
    "            mean_health = health_exp.mean()\n",
    "            mean_no_health = no_health_exp.mean()\n",
    "            \n",
    "            plt.annotate(\n",
    "                f'With complaint: {mean_health:.1f} years\\nWithout complaint: {mean_no_health:.1f} years',\n",
    "                xy=(0.5, 0.85),\n",
    "                xycoords='axes fraction',\n",
    "                ha='center',\n",
    "                va='top',\n",
    "                bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "            )\n",
    "        \n",
    "        plt.title(f'Agricultural Experience by {health_var}', fontsize=14)\n",
    "        plt.xlabel(health_var, fontsize=12)\n",
    "        plt.ylabel('Agricultural Experience (years)', fontsize=12)\n",
    "        plt.xticks([0, 1], ['No', 'Yes'])\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(exp_dir, f\"experience_vs_{health_var}.png\")\n",
    "        plt.savefig(fig_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "    \n",
    "    # 2. Analyze correlation between experience and health metrics\n",
    "    health_metrics = ['BMI', 'TAS', 'TAD']\n",
    "    available_metrics = [var for var in health_metrics if var in data.columns]\n",
    "    \n",
    "    for metric in available_metrics:\n",
    "        logger.info(f\"  Analyzing experience vs. {metric}\")\n",
    "        \n",
    "        # Calculate correlation\n",
    "        corr, p = stats.pearsonr(data['Ancienneté agricole'], data[metric])\n",
    "        \n",
    "        # Create scatter plot\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        sns.regplot(\n",
    "            x='Ancienneté agricole',\n",
    "            y=metric,\n",
    "            data=data,\n",
    "            scatter_kws={'alpha': 0.6},\n",
    "            line_kws={'color': 'red'}\n",
    "        )\n",
    "        \n",
    "        # Add correlation text\n",
    "        plt.annotate(\n",
    "            f'r = {corr:.2f}, p = {p:.4f}',\n",
    "            xy=(0.05, 0.95),\n",
    "            xycoords='axes fraction',\n",
    "            ha='left',\n",
    "            va='top',\n",
    "            bbox=dict(boxstyle='round', fc='white', alpha=0.8)\n",
    "        )\n",
    "        \n",
    "        plt.title(f'Relationship between Agricultural Experience and {metric}', fontsize=14)\n",
    "        plt.xlabel('Agricultural Experience (years)', fontsize=12)\n",
    "        plt.ylabel(metric, fontsize=12)\n",
    "        plt.grid(True, linestyle='--', alpha=0.7)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(exp_dir, f\"experience_vs_{metric}.png\")\n",
    "        plt.savefig(fig_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"    Saved Experience vs {metric} visualization to {fig_path}\")\n",
    "    \n",
    "    # 3. Create experience groups and analyze health outcomes\n",
    "    logger.info(\"  Analyzing health outcomes by experience groups\")\n",
    "    \n",
    "    # Create experience groups\n",
    "    data['Experience_Group'] = pd.cut(\n",
    "        data['Ancienneté agricole'],\n",
    "        bins=[0, 5, 10, 20, 50],\n",
    "        labels=['<5 yrs', '5-10 yrs', '10-20 yrs', '>20 yrs']\n",
    "    )\n",
    "    \n",
    "    # Compare health outcomes across experience groups\n",
    "    for health_var in health_vars:\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Calculate percentages\n",
    "        props = pd.crosstab(\n",
    "            data['Experience_Group'], \n",
    "            data[health_var],\n",
    "            normalize='index'\n",
    "        ) * 100\n",
    "        \n",
    "        # Create bar chart for the \"Yes\" column (health complaint present)\n",
    "        ax = props[1].plot(kind='bar')\n",
    "        \n",
    "        plt.title(f'{health_var} by Agricultural Experience', fontsize=14)\n",
    "        plt.xlabel('Years of Agricultural Experience', fontsize=12)\n",
    "        plt.ylabel(f'Percentage with {health_var}', fontsize=12)\n",
    "        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, v in enumerate(props[1]):\n",
    "            ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        # Save figure\n",
    "        fig_path = os.path.join(exp_dir, f\"experience_group_vs_{health_var}.png\")\n",
    "        plt.savefig(fig_path, dpi=300)\n",
    "        plt.close()\n",
    "        logger.info(f\"    Saved Experience Groups vs {health_var} visualization\")\n",
    "\n",
    "def multivariate_health_model(data):\n",
    "    \"\"\"Build multivariate models to predict health outcomes\"\"\"\n",
    "    logger.info(\"Building multivariate models for health outcomes...\")\n",
    "    \n",
    "    # Check if we have any health outcome variables\n",
    "    health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "    \n",
    "    if not health_vars:\n",
    "        logger.warning(\"No health outcome variables available for modeling\")\n",
    "        return\n",
    "    \n",
    "    # Create directory for models\n",
    "    models_dir = os.path.join(output_dir, \"multivariate_models\")\n",
    "    os.makedirs(models_dir, exist_ok=True)\n",
    "    \n",
    "    # For each health outcome, create a logistic regression model\n",
    "    for health_var in health_vars:\n",
    "        logger.info(f\"  Building model for {health_var}\")\n",
    "        \n",
    "        # Define potential predictors\n",
    "        predictors = [\n",
    "            'Age', 'BMI', 'Hours_Per_Week', 'exposed_to_tabouna',\n",
    "            'is_smoker', 'uses_neffa', 'Ancienneté agricole'\n",
    "        ]\n",
    "        \n",
    "        # Only include predictors that exist in the data\n",
    "        available_predictors = [var for var in predictors if var in data.columns]\n",
    "        \n",
    "        if len(available_predictors) < 3:\n",
    "            logger.warning(f\"    Insufficient predictors for {health_var}\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare data for model (drop missing values)\n",
    "        model_data = data.dropna(subset=available_predictors + [health_var])\n",
    "        \n",
    "        if len(model_data) < 20:\n",
    "            logger.warning(f\"    Insufficient data for {health_var} model\")\n",
    "            continue\n",
    "        \n",
    "        # Build formula for statsmodels\n",
    "        formula = f\"{health_var} ~ \" + \" + \".join(available_predictors)\n",
    "        \n",
    "        try:\n",
    "            # Fit logistic regression model\n",
    "            model = glm(formula=formula, data=model_data, family=sm.families.Binomial()).fit()\n",
    "            \n",
    "            # Save model summary\n",
    "            with open(os.path.join(models_dir, f\"{health_var}_model_summary.txt\"), 'w') as f:\n",
    "                f.write(model.summary().as_text())\n",
    "            \n",
    "            # Extract odds ratios and confidence intervals\n",
    "            params = model.params\n",
    "            conf_int = model.conf_int()\n",
    "            \n",
    "            odds_ratios = pd.DataFrame({\n",
    "                'Variable': params.index,\n",
    "                'Coefficient': params.values,\n",
    "                'Odds_Ratio': np.exp(params.values),\n",
    "                'CI_Lower': np.exp(conf_int[0]),\n",
    "                'CI_Upper': np.exp(conf_int[1]),\n",
    "                'P_value': model.pvalues,\n",
    "                'Significant': model.pvalues < 0.05\n",
    "            })\n",
    "            \n",
    "            # Save odds ratios\n",
    "            odds_path = os.path.join(models_dir, f\"{health_var}_odds_ratios.csv\")\n",
    "            odds_ratios.to_csv(odds_path, index=False)\n",
    "            logger.info(f\"    Saved odds ratios to {odds_path}\")\n",
    "            \n",
    "            # Create forest plot of odds ratios\n",
    "            # Filter out intercept for visualization\n",
    "            plot_odds = odds_ratios[odds_ratios['Variable'] != 'Intercept'].copy()\n",
    "            \n",
    "            if not plot_odds.empty:\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                # Create forest plot\n",
    "                plt.errorbar(\n",
    "                    x=plot_odds['Odds_Ratio'],\n",
    "                    y=range(len(plot_odds)),\n",
    "                    xerr=[plot_odds['Odds_Ratio'] - plot_odds['CI_Lower'], \n",
    "                         plot_odds['CI_Upper'] - plot_odds['Odds_Ratio']],\n",
    "                    fmt='o',\n",
    "                    capsize=5\n",
    "                )\n",
    "                \n",
    "                # Add vertical line at OR=1 (no effect)\n",
    "                plt.axvline(1, color='gray', linestyle='--', alpha=0.7)\n",
    "                \n",
    "                # Format y-axis with variable names\n",
    "                plt.yticks(range(len(plot_odds)), plot_odds['Variable'])\n",
    "                \n",
    "                plt.title(f'Odds Ratios for {health_var}', fontsize=14)\n",
    "                plt.xlabel('Odds Ratio (log scale)', fontsize=12)\n",
    "                plt.xscale('log')  # Use log scale for better visualization\n",
    "                \n",
    "                # Set reasonable x-axis limits\n",
    "                max_upper = min(plot_odds['CI_Upper'].max(), 10)  # Cap at 10 for readability\n",
    "                min_lower = max(plot_odds['CI_Lower'].min(), 0.1)  # Floor at 0.1 for readability\n",
    "                plt.xlim(min_lower, max_upper)\n",
    "                \n",
    "                plt.grid(axis='x', linestyle='--', alpha=0.7)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save figure\n",
    "                fig_path = os.path.join(models_dir, f\"{health_var}_odds_ratios_plot.png\")\n",
    "                plt.savefig(fig_path, dpi=300)\n",
    "                plt.close()\n",
    "                logger.info(f\"    Saved odds ratios plot to {fig_path}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            logger.error(f\"    Error building model for {health_var}: {str(e)}\")\n",
    "\n",
    "def create_summary_report(data):\n",
    "    \"\"\"Create a summary report of key health findings\"\"\"\n",
    "    logger.info(\"Creating health analysis summary report...\")\n",
    "    \n",
    "    # Create list to store findings\n",
    "    findings = []\n",
    "    \n",
    "    # 1. Check for BMI analysis results\n",
    "    bmi_health_path = os.path.join(output_dir, \"bmi_analysis/bmi_health_chi_square.csv\")\n",
    "    if os.path.exists(bmi_health_path):\n",
    "        try:\n",
    "            bmi_results = pd.read_csv(bmi_health_path)\n",
    "            sig_results = bmi_results[bmi_results['Significant']]\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                findings.append(\n",
    "                    f\"BMI category is significantly associated with {row['Health_Variable']} \" +\n",
    "                    f\"(Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f})\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading BMI results: {str(e)}\")\n",
    "    \n",
    "    # 2. Check for blood pressure correlations\n",
    "    bp_corr_path = os.path.join(output_dir, \"blood_pressure/bmi_bp_correlations.csv\")\n",
    "    if os.path.exists(bp_corr_path):\n",
    "        try:\n",
    "            bp_results = pd.read_csv(bp_corr_path)\n",
    "            sig_results = bp_results[bp_results['Significant']]\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                findings.append(\n",
    "                    f\"BMI is significantly correlated with {row['Variable']} \" +\n",
    "                    f\"(r={row['Correlation']:.2f}, p={row['P_value']:.4f})\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading BP correlation results: {str(e)}\")\n",
    "    \n",
    "    # 3. Check for traditional practices results\n",
    "    trad_path = os.path.join(output_dir, \"traditional_practices/tabouna_respiratory_results.csv\")\n",
    "    if os.path.exists(trad_path):\n",
    "        try:\n",
    "            trad_results = pd.read_csv(trad_path)\n",
    "            if 'Significant' in trad_results.columns and trad_results['Significant'].any():\n",
    "                row = trad_results.iloc[0]\n",
    "                findings.append(\n",
    "                    f\"Tabouna smoke exposure is significantly associated with respiratory issues \" +\n",
    "                    f\"(Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f}, \" +\n",
    "                    f\"Risk Ratio={row['Risk_Ratio']:.2f})\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading traditional practices results: {str(e)}\")\n",
    "    \n",
    "    # 4. Check for work pattern results\n",
    "    work_path = os.path.join(output_dir, \"work_patterns/employment_status_health.csv\")\n",
    "    if os.path.exists(work_path):\n",
    "        try:\n",
    "            work_results = pd.read_csv(work_path)\n",
    "            sig_results = work_results[work_results['Significant']]\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                findings.append(\n",
    "                    f\"Employment status (permanent vs. seasonal) is significantly associated with \" +\n",
    "                    f\"{row['Health_Outcome']} (Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f})\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading work pattern results: {str(e)}\")\n",
    "    \n",
    "    # 5. Check for transportation results\n",
    "    trans_path = os.path.join(output_dir, \"transportation/walking_health_results.csv\")\n",
    "    if os.path.exists(trans_path):\n",
    "        try:\n",
    "            trans_results = pd.read_csv(trans_path)\n",
    "            sig_results = trans_results[trans_results['Significant']]\n",
    "            \n",
    "            for _, row in sig_results.iterrows():\n",
    "                findings.append(\n",
    "                    f\"Walking as transportation is significantly associated with {row['Health_Outcome']} \" +\n",
    "                    f\"(Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f}, \" +\n",
    "                    f\"Risk Ratio={row['Risk_Ratio']:.2f})\"\n",
    "                )\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error reading transportation results: {str(e)}\")\n",
    "    \n",
    "    # 6. Check for multivariate model results\n",
    "    models_dir = os.path.join(output_dir, \"multivariate_models\")\n",
    "    if os.path.exists(models_dir):\n",
    "        for file in os.listdir(models_dir):\n",
    "            if file.endswith(\"_odds_ratios.csv\"):\n",
    "                try:\n",
    "                    model_results = pd.read_csv(os.path.join(models_dir, file))\n",
    "                    sig_results = model_results[model_results['Significant'] & (model_results['Variable'] != 'Intercept')]\n",
    "                    \n",
    "                    health_outcome = file.split('_odds_ratios.csv')[0]\n",
    "                    \n",
    "                    for _, row in sig_results.iterrows():\n",
    "                        direction = \"increase\" if row['Odds_Ratio'] > 1 else \"decrease\"\n",
    "                        findings.append(\n",
    "                            f\"{row['Variable']} is significantly associated with a {direction} in {health_outcome} \" +\n",
    "                            f\"(OR={row['Odds_Ratio']:.2f}, 95% CI: {row['CI_Lower']:.2f}-{row['CI_Upper']:.2f}, \" +\n",
    "                            f\"p={row['P_value']:.4f})\"\n",
    "                        )\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"Error reading model results: {str(e)}\")\n",
    "    \n",
    "    # Create summary report\n",
    "    with open(os.path.join(output_dir, \"health_analysis_summary.txt\"), 'w') as f:\n",
    "        f.write(\"# Health Analysis Summary Report\\n\\n\")\n",
    "        f.write(f\"Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\\n\")\n",
    "        f.write(f\"Dataset: Female Farmers Health Study\\n\")\n",
    "        f.write(f\"Sample Size: {len(data)}\\n\\n\")\n",
    "        \n",
    "        f.write(\"## Key Findings\\n\\n\")\n",
    "        \n",
    "        if findings:\n",
    "            for i, finding in enumerate(findings, 1):\n",
    "                f.write(f\"{i}. {finding}\\n\")\n",
    "        else:\n",
    "            f.write(\"No significant health relationships were identified.\\n\")\n",
    "        \n",
    "        f.write(\"\\n## Analysis Methods\\n\\n\")\n",
    "        f.write(\"The following health analyses were performed:\\n\")\n",
    "        f.write(\"- Relationships between BMI and health outcomes\\n\")\n",
    "        f.write(\"- Blood pressure analysis and its determinants\\n\")\n",
    "        f.write(\"- Impact of traditional practices (Tabouna smoke, Neffa) on health\\n\")\n",
    "        f.write(\"- Work patterns and health relationships\\n\")\n",
    "        f.write(\"- Transportation method and health outcomes\\n\")\n",
    "        f.write(\"- Agricultural experience and health metrics\\n\")\n",
    "        f.write(\"- Multivariate models to predict specific health outcomes\\n\")\n",
    "    \n",
    "    logger.info(\"Health analysis summary report created\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to execute all missing health analyses\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        data = load_data()\n",
    "        \n",
    "        # Prepare data for analysis\n",
    "        analysis_data = prepare_data_for_analysis(data)\n",
    "        \n",
    "        # Traditional practices analysis\n",
    "        traditional_practices_analysis(analysis_data)\n",
    "        \n",
    "        # Transportation method analysis\n",
    "        transportation_health_analysis(analysis_data)\n",
    "        \n",
    "        # Agricultural experience analysis\n",
    "        experience_health_analysis(analysis_data)\n",
    "        \n",
    "        # Multivariate health models\n",
    "        multivariate_health_model(analysis_data)\n",
    "        \n",
    "        # Create summary report\n",
    "        create_summary_report(analysis_data)\n",
    "        \n",
    "        logger.info(f\"All missing health analyses completed and saved to {output_dir}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error in health analysis: {str(e)}\")\n",
    "        logger.exception(\"Detailed error information:\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() == no_health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-01 15:07:24,193 - INFO - Loading the dataset...\n",
      "2025-04-01 15:07:24,284 - INFO - Successfully loaded data from fixed_female_farmers_data.xlsx\n",
      "2025-04-01 15:07:24,285 - INFO - Dataset loaded with 80 rows and 37 columns\n",
      "2025-04-01 15:07:24,286 - INFO - Columns in dataset: N°, Age, Situation maritale, Nb enfants, Nb pers à charge, Domicile, Niveau socio-économique, Tabagisme, Neffa, Fumées de Tabouna, AT en milieu agricole, H travail / jour, Mécanisme AT, Ménopause, Age ménopause, Antécédents gynéco, Ancienneté agricole, Catégorie professionnelle, Statut, J travail / Sem, Masque pour pesticides, Bottes, Niveau scolaire, Gants, Casquette/Mdhalla, Manteau imperméable, Poids, Taille, TAS, TAD, GAD, Produits chimiques utilisés, Produits biologiques utilisés, Engrais utilisés, Contraintes thermiques, Moyen de transport, Profession du mari\n",
      "2025-04-01 15:07:24,288 - INFO - Debugging key variables...\n",
      "2025-04-01 15:07:24,290 - INFO - Column found: Moyen de transport\n",
      "2025-04-01 15:07:24,294 - INFO - Values: {'a pieds': 60, 'camion non protégé': 10, 'charette': 5, 'bus transport public': 2, 'voiture': 2, 'charrette': 1}\n",
      "2025-04-01 15:07:24,295 - INFO - Column found: Fumées de Tabouna\n",
      "2025-04-01 15:07:24,300 - INFO - Values: {'oui': 59, 'non': 21}\n",
      "2025-04-01 15:07:24,303 - INFO - Column found: Tabagisme\n",
      "2025-04-01 15:07:24,305 - INFO - Values: {'non': 65, 'passif': 15}\n",
      "2025-04-01 15:07:24,307 - INFO - Column found: Neffa\n",
      "2025-04-01 15:07:24,309 - INFO - Values: {'non': 80}\n",
      "2025-04-01 15:07:24,310 - INFO - Preparing data for analysis...\n",
      "2025-04-01 15:07:24,312 - INFO - Found 'Moyen de transport' column\n",
      "2025-04-01 15:07:24,313 - INFO - Transportation mode counts: {'a pieds': 60, 'camion non protégé': 10, 'charette': 5, 'bus transport public': 2, 'voiture': 2, 'charrette': 1}\n",
      "2025-04-01 15:07:24,315 - INFO - Using 'a pieds' as walking value\n",
      "2025-04-01 15:07:24,322 - INFO - Created binary transportation variable: {1: 60, 0: 20}\n",
      "2025-04-01 15:07:24,325 - INFO - Fumées de Tabouna values: {'oui': 59, 'non': 21}\n",
      "2025-04-01 15:07:24,326 - INFO - Using 'oui' as affirmative value for Fumées de Tabouna\n",
      "2025-04-01 15:07:24,329 - INFO - Created binary variable exposed_to_tabouna: {1: 59, 0: 21}\n",
      "2025-04-01 15:07:24,337 - INFO - Tabagisme values: {'non': 65, 'passif': 15}\n",
      "2025-04-01 15:07:24,341 - WARNING - Could not find affirmative value for Tabagisme, using most common value\n",
      "2025-04-01 15:07:24,343 - INFO - Created binary variable is_smoker: {1: 65, 0: 15}\n",
      "2025-04-01 15:07:24,345 - INFO - Neffa values: {'non': 80}\n",
      "2025-04-01 15:07:24,346 - WARNING - Could not find affirmative value for Neffa, using most common value\n",
      "2025-04-01 15:07:24,351 - INFO - Created binary variable uses_neffa: {1: 80}\n",
      "2025-04-01 15:07:24,354 - INFO - Running transportation health analysis with enhanced diagnostics...\n",
      "2025-04-01 15:07:24,355 - INFO - Analyzing transportation method and health...\n",
      "2025-04-01 15:07:24,358 - INFO - transport_walking counts: {1: 60, 0: 20}\n",
      "2025-04-01 15:07:24,359 - INFO - Found 0 health variables: []\n",
      "2025-04-01 15:07:24,360 - ERROR - No health variables found, cannot proceed with analysis\n",
      "2025-04-01 15:07:24,361 - INFO - Transportation analysis failed\n",
      "2025-04-01 15:07:24,363 - INFO - Running traditional practices analysis with enhanced diagnostics...\n",
      "2025-04-01 15:07:24,365 - INFO - Analyzing traditional practices and health...\n",
      "2025-04-01 15:07:24,367 - INFO - exposed_to_tabouna counts: {1: 59, 0: 21}\n",
      "2025-04-01 15:07:24,371 - INFO - uses_neffa counts: {1: 80}\n",
      "2025-04-01 15:07:24,374 - INFO - Found 0 health variables for traditional practices analysis\n",
      "2025-04-01 15:07:24,374 - ERROR - No health variables found, cannot proceed with analysis\n",
      "2025-04-01 15:07:24,375 - INFO - Traditional practices analysis failed\n",
      "2025-04-01 15:07:24,377 - INFO - Updating summary report...\n",
      "2025-04-01 15:07:24,378 - INFO - Updating health analysis summary report...\n",
      "2025-04-01 15:07:24,379 - WARNING - File not found: C:/Users/SelmaB/Desktop/Project/Analysis/2.Anova part two all determinants/results/health_analysis\\bmi_analysis/bmi_health_chi_square.csv\n",
      "2025-04-01 15:07:24,380 - INFO - Found 0 significant BMI findings\n",
      "2025-04-01 15:07:24,384 - WARNING - File not found: C:/Users/SelmaB/Desktop/Project/Analysis/2.Anova part two all determinants/results/health_analysis\\blood_pressure/bmi_bp_correlations.csv\n",
      "2025-04-01 15:07:24,387 - INFO - Found 0 significant blood pressure correlations\n",
      "2025-04-01 15:07:24,388 - WARNING - File not found: C:/Users/SelmaB/Desktop/Project/Analysis/2.Anova part two all determinants/results/health_analysis\\traditional_practices/tabouna_respiratory_results.csv\n",
      "2025-04-01 15:07:24,389 - INFO - Found 0 significant traditional practices findings\n",
      "2025-04-01 15:07:24,391 - WARNING - File not found: C:/Users/SelmaB/Desktop/Project/Analysis/2.Anova part two all determinants/results/health_analysis\\transportation/walking_health_results.csv\n",
      "2025-04-01 15:07:24,392 - INFO - Found 0 significant transportation findings\n",
      "2025-04-01 15:07:24,393 - INFO - Summary report updated successfully\n",
      "2025-04-01 15:07:24,395 - INFO - Analysis fixes completed\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\"\"\"\n",
    "Fix Transportation and Traditional Practices Analyses for Female Farmers\n",
    "This script focuses on completing the problematic analyses:\n",
    "1. Transportation health analysis\n",
    "2. Traditional practices analysis\n",
    "3. Update summary report\n",
    "\n",
    "Author: [Your Name]\n",
    "Date: April 2, 2025\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import os\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set output directory for results\n",
    "output_dir = 'C:/Users/SelmaB/Desktop/Project/Analysis/2.Anova part two all determinants/results/health_analysis'\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Load the preprocessed dataset with detailed error logging\"\"\"\n",
    "    logger.info(\"Loading the dataset...\")\n",
    "    \n",
    "    # List potential file paths\n",
    "    potential_paths = [\n",
    "        'C:/Users/SelmaB/Desktop/Project/Analysis/fixed_female_farmers_data.xlsx',\n",
    "        'fixed_female_farmers_data.xlsx',\n",
    "        'C:/Users/SelmaB/Desktop/Project/fixed_female_farmers_data.xlsx',\n",
    "        'C:/Users/SelmaB/Desktop/fixed_female_farmers_data.xlsx'\n",
    "    ]\n",
    "    \n",
    "    data = None\n",
    "    errors = []\n",
    "    \n",
    "    # Try each path\n",
    "    for path in potential_paths:\n",
    "        try:\n",
    "            data = pd.read_excel(path)\n",
    "            logger.info(f\"Successfully loaded data from {path}\")\n",
    "            logger.info(f\"Dataset loaded with {data.shape[0]} rows and {data.shape[1]} columns\")\n",
    "            \n",
    "            # Print column names to debug\n",
    "            logger.info(f\"Columns in dataset: {', '.join(data.columns)}\")\n",
    "            \n",
    "            return data\n",
    "        except Exception as e:\n",
    "            errors.append(f\"Error loading from {path}: {str(e)}\")\n",
    "    \n",
    "    # If we reach here, all paths failed\n",
    "    for error in errors:\n",
    "        logger.error(error)\n",
    "    \n",
    "    raise FileNotFoundError(\"Could not find or load the dataset from any expected location\")\n",
    "\n",
    "def debug_data(data):\n",
    "    \"\"\"Print detailed information about key variables for debugging\"\"\"\n",
    "    logger.info(\"Debugging key variables...\")\n",
    "    \n",
    "    # Check transportation variable\n",
    "    transport_cols = [col for col in data.columns if 'transport' in col.lower()]\n",
    "    if transport_cols:\n",
    "        for col in transport_cols:\n",
    "            logger.info(f\"Column found: {col}\")\n",
    "            logger.info(f\"Values: {data[col].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        logger.warning(\"No transportation column found with 'transport' in the name\")\n",
    "        # Look for potential transportation columns\n",
    "        potential_cols = [col for col in data.columns if col.startswith('Mo') or 'déplacement' in col.lower()]\n",
    "        if potential_cols:\n",
    "            logger.info(f\"Potential transportation columns: {potential_cols}\")\n",
    "            for col in potential_cols:\n",
    "                logger.info(f\"Values in {col}: {data[col].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Check traditional practices variables\n",
    "    trad_cols = ['Fumées de Tabouna', 'Tabagisme', 'Neffa']\n",
    "    for col in trad_cols:\n",
    "        if col in data.columns:\n",
    "            logger.info(f\"Column found: {col}\")\n",
    "            logger.info(f\"Values: {data[col].value_counts().to_dict()}\")\n",
    "        else:\n",
    "            logger.warning(f\"Traditional practice column not found: {col}\")\n",
    "    \n",
    "    # Check health outcome variables\n",
    "    health_cols = [col for col in data.columns if 'Troubles' in col]\n",
    "    for col in health_cols:\n",
    "        logger.info(f\"Health column: {col}\")\n",
    "        # Count non-null values\n",
    "        non_null = data[col].notna().sum()\n",
    "        logger.info(f\"Non-null values: {non_null} ({non_null/len(data)*100:.1f}%)\")\n",
    "    \n",
    "    return\n",
    "\n",
    "def prepare_data_for_analysis(data):\n",
    "    \"\"\"\n",
    "    Prepare data for health analysis, with additional checks and diagnostics\n",
    "    \"\"\"\n",
    "    logger.info(\"Preparing data for analysis...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Check for transportation variable and create if needed\n",
    "    if 'Moyen de transport' in df.columns:\n",
    "        logger.info(\"Found 'Moyen de transport' column\")\n",
    "        \n",
    "        # Show value counts\n",
    "        counts = df['Moyen de transport'].value_counts()\n",
    "        logger.info(f\"Transportation mode counts: {counts.to_dict()}\")\n",
    "        \n",
    "        # Check if 'a pieds' is in the values (with variations)\n",
    "        potential_walking = [val for val in counts.index if 'pied' in str(val).lower()]\n",
    "        if potential_walking:\n",
    "            walking_value = potential_walking[0]\n",
    "            logger.info(f\"Using '{walking_value}' as walking value\")\n",
    "            df['transport_walking'] = (df['Moyen de transport'] == walking_value).astype(int)\n",
    "        else:\n",
    "            logger.warning(\"Could not find 'a pieds' value, using most common value as reference\")\n",
    "            most_common = counts.index[0]\n",
    "            df['transport_walking'] = (df['Moyen de transport'] == most_common).astype(int)\n",
    "        \n",
    "        logger.info(f\"Created binary transportation variable: {df['transport_walking'].value_counts().to_dict()}\")\n",
    "    else:\n",
    "        logger.warning(\"'Moyen de transport' column not found, checking alternatives\")\n",
    "        # Try to find alternative transportation column\n",
    "        transport_cols = [col for col in df.columns if 'transport' in col.lower() or 'déplacement' in col.lower()]\n",
    "        if transport_cols:\n",
    "            transport_col = transport_cols[0]\n",
    "            logger.info(f\"Using alternative column: {transport_col}\")\n",
    "            # Count values\n",
    "            counts = df[transport_col].value_counts()\n",
    "            logger.info(f\"Values: {counts.to_dict()}\")\n",
    "            \n",
    "            # Create binary variable using most common value\n",
    "            most_common = counts.index[0]\n",
    "            df['transport_walking'] = (df[transport_col] == most_common).astype(int)\n",
    "        else:\n",
    "            logger.error(\"No transportation column found, cannot create transport_walking variable\")\n",
    "    \n",
    "    # Create binary indicators for traditional practices\n",
    "    trad_practices = {\n",
    "        'Fumées de Tabouna': 'exposed_to_tabouna',\n",
    "        'Tabagisme': 'is_smoker',\n",
    "        'Neffa': 'uses_neffa'\n",
    "    }\n",
    "    \n",
    "    for orig_col, new_col in trad_practices.items():\n",
    "        if orig_col in df.columns:\n",
    "            # Check value counts\n",
    "            counts = df[orig_col].value_counts()\n",
    "            logger.info(f\"{orig_col} values: {counts.to_dict()}\")\n",
    "            \n",
    "            # Look for 'oui' or similar affirmative values\n",
    "            affirmative = [val for val in counts.index if str(val).lower() in ['oui', 'yes', '1', 'true']]\n",
    "            if affirmative:\n",
    "                affirmative_val = affirmative[0]\n",
    "                logger.info(f\"Using '{affirmative_val}' as affirmative value for {orig_col}\")\n",
    "                df[new_col] = (df[orig_col] == affirmative_val).astype(int)\n",
    "            else:\n",
    "                logger.warning(f\"Could not find affirmative value for {orig_col}, using most common value\")\n",
    "                most_common = counts.index[0]\n",
    "                df[new_col] = (df[orig_col] == most_common).astype(int)\n",
    "            \n",
    "            logger.info(f\"Created binary variable {new_col}: {df[new_col].value_counts().to_dict()}\")\n",
    "        else:\n",
    "            logger.warning(f\"Column not found: {orig_col}\")\n",
    "    \n",
    "    # Create binary health indicators\n",
    "    health_categories = [col for col in df.columns if 'Troubles' in col]\n",
    "    \n",
    "    for category in health_categories:\n",
    "        binary_var = f\"has_{category.lower().replace('-', '_').replace(' ', '_').replace('/', '_')}\"\n",
    "        df[binary_var] = df[category].notna().astype(int)\n",
    "        logger.info(f\"Created binary health variable: {binary_var}: {df[binary_var].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Create a variable for any health complaint\n",
    "    if health_categories:\n",
    "        df['has_any_health_complaint'] = df[health_categories].notna().any(axis=1).astype(int)\n",
    "        logger.info(f\"Created 'has_any_health_complaint' variable: {df['has_any_health_complaint'].value_counts().to_dict()}\")\n",
    "    \n",
    "    return df\n",
    "\n",
    "def transportation_health_analysis(data):\n",
    "    \"\"\"Analyze relationship between transportation method and health with enhanced debugging\"\"\"\n",
    "    logger.info(\"Analyzing transportation method and health...\")\n",
    "    \n",
    "    # Check for transportation variables\n",
    "    if 'transport_walking' not in data.columns:\n",
    "        logger.error(\"transport_walking variable not found, cannot proceed with analysis\")\n",
    "        return False\n",
    "    \n",
    "    # Log counts\n",
    "    logger.info(f\"transport_walking counts: {data['transport_walking'].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Create directory for transportation analysis\n",
    "    trans_dir = os.path.join(output_dir, \"transportation\")\n",
    "    os.makedirs(trans_dir, exist_ok=True)\n",
    "    \n",
    "    # Get health variables\n",
    "    health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "    logger.info(f\"Found {len(health_vars)} health variables: {health_vars}\")\n",
    "    \n",
    "    if not health_vars:\n",
    "        logger.error(\"No health variables found, cannot proceed with analysis\")\n",
    "        return False\n",
    "    \n",
    "    # 1. Analyze relationship between walking and health complaints\n",
    "    results = []\n",
    "    created_visualizations = False\n",
    "    \n",
    "    for health_var in health_vars:\n",
    "        logger.info(f\"  Analyzing transportation vs. {health_var}\")\n",
    "        \n",
    "        # Count values in the health variable\n",
    "        logger.info(f\"  {health_var} counts: {data[health_var].value_counts().to_dict()}\")\n",
    "        \n",
    "        try:\n",
    "            # Create contingency table\n",
    "            contingency = pd.crosstab(data['transport_walking'], data[health_var])\n",
    "            logger.info(f\"  Contingency table:\\n{contingency}\")\n",
    "            \n",
    "            # Check if we have enough data\n",
    "            if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "                # Check for zero counts\n",
    "                has_zeros = (contingency == 0).any().any()\n",
    "                if has_zeros:\n",
    "                    logger.warning(f\"  Contingency table contains zeros, which may affect chi-square test\")\n",
    "                \n",
    "                # Perform chi-square test\n",
    "                chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "                \n",
    "                # Calculate risk ratio if possible\n",
    "                try:\n",
    "                    if 1 in contingency.index and 0 in contingency.index and 1 in contingency.columns:\n",
    "                        risk_walking = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "                        risk_other = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "                        risk_ratio = risk_walking / risk_other\n",
    "                    else:\n",
    "                        risk_ratio = np.nan\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"  Error calculating risk ratio: {str(e)}\")\n",
    "                    risk_ratio = np.nan\n",
    "                \n",
    "                results.append({\n",
    "                    'Health_Outcome': health_var,\n",
    "                    'Chi_Square': chi2,\n",
    "                    'P_value': p,\n",
    "                    'Risk_Ratio': risk_ratio,\n",
    "                    'Significant': p < 0.05\n",
    "                })\n",
    "                \n",
    "                # Create visualization for this health variable regardless of significance\n",
    "                try:\n",
    "                    plt.figure(figsize=(10, 6))\n",
    "                    \n",
    "                    # Calculate percentages\n",
    "                    props = pd.crosstab(\n",
    "                        data['transport_walking'], \n",
    "                        data[health_var],\n",
    "                        normalize='index'\n",
    "                    ) * 100\n",
    "                    \n",
    "                    # Create bar chart for the \"Yes\" column (health complaint present)\n",
    "                    ax = props[1].plot(kind='bar')\n",
    "                    \n",
    "                    plt.title(f'{health_var} by Transportation Method (p={p:.4f})', fontsize=14)\n",
    "                    plt.xlabel('Walking as Transportation', fontsize=12)\n",
    "                    plt.ylabel(f'Percentage with {health_var}', fontsize=12)\n",
    "                    plt.xticks([0, 1], ['No', 'Yes'])\n",
    "                    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                    \n",
    "                    # Add percentage labels\n",
    "                    for i, v in enumerate(props[1]):\n",
    "                        ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "                    \n",
    "                    plt.tight_layout()\n",
    "                    \n",
    "                    # Save figure\n",
    "                    fig_path = os.path.join(trans_dir, f\"walking_vs_{health_var}.png\")\n",
    "                    plt.savefig(fig_path, dpi=300)\n",
    "                    plt.close()\n",
    "                    logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "                    created_visualizations = True\n",
    "                except Exception as e:\n",
    "                    logger.error(f\"  Error creating visualization: {str(e)}\")\n",
    "            else:\n",
    "                logger.warning(f\"  Insufficient data for chi-square test for {health_var}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"  Error analyzing {health_var}: {str(e)}\")\n",
    "    \n",
    "    # Save results\n",
    "    if results:\n",
    "        try:\n",
    "            results_df = pd.DataFrame(results)\n",
    "            results_path = os.path.join(trans_dir, \"walking_health_results.csv\")\n",
    "            results_df.to_csv(results_path, index=False)\n",
    "            logger.info(f\"  Saved walking vs. health results to {results_path}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"  Error saving results: {str(e)}\")\n",
    "    else:\n",
    "        logger.warning(\"  No valid results to save for transportation analysis\")\n",
    "    \n",
    "    return created_visualizations\n",
    "\n",
    "def traditional_practices_analysis(data):\n",
    "    \"\"\"Analyze the impact of traditional practices on health with enhanced debugging\"\"\"\n",
    "    logger.info(\"Analyzing traditional practices and health...\")\n",
    "    \n",
    "    # Check for traditional practice variables\n",
    "    trad_vars = ['exposed_to_tabouna', 'uses_neffa']\n",
    "    available_vars = [var for var in trad_vars if var in data.columns]\n",
    "    \n",
    "    if not available_vars:\n",
    "        logger.error(\"No traditional practice variables found, cannot proceed with analysis\")\n",
    "        return False\n",
    "    \n",
    "    # Log counts for available variables\n",
    "    for var in available_vars:\n",
    "        logger.info(f\"{var} counts: {data[var].value_counts().to_dict()}\")\n",
    "    \n",
    "    # Create directory for traditional practices analysis\n",
    "    trad_dir = os.path.join(output_dir, \"traditional_practices\")\n",
    "    os.makedirs(trad_dir, exist_ok=True)\n",
    "    \n",
    "    # Get health variables\n",
    "    health_vars = [var for var in data.columns if var.startswith('has_')]\n",
    "    logger.info(f\"Found {len(health_vars)} health variables for traditional practices analysis\")\n",
    "    \n",
    "    if not health_vars:\n",
    "        logger.error(\"No health variables found, cannot proceed with analysis\")\n",
    "        return False\n",
    "    \n",
    "    created_visualizations = False\n",
    "    \n",
    "    # Analyze each traditional practice\n",
    "    for practice_var in available_vars:\n",
    "        logger.info(f\"  Analyzing {practice_var} and health outcomes\")\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        for health_var in health_vars:\n",
    "            try:\n",
    "                # Create contingency table\n",
    "                contingency = pd.crosstab(data[practice_var], data[health_var])\n",
    "                logger.info(f\"  Contingency table for {practice_var} vs {health_var}:\\n{contingency}\")\n",
    "                \n",
    "                # Check if we have enough data\n",
    "                if contingency.shape[0] > 1 and contingency.shape[1] > 1:\n",
    "                    # Perform chi-square test\n",
    "                    chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "                    \n",
    "                    # Calculate risk ratio if possible\n",
    "                    try:\n",
    "                        if 1 in contingency.index and 0 in contingency.index and 1 in contingency.columns:\n",
    "                            risk_exposed = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "                            risk_unexposed = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "                            risk_ratio = risk_exposed / risk_unexposed\n",
    "                        else:\n",
    "                            risk_ratio = np.nan\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"  Error calculating risk ratio: {str(e)}\")\n",
    "                        risk_ratio = np.nan\n",
    "                    \n",
    "                    results.append({\n",
    "                        'Health_Outcome': health_var,\n",
    "                        'Chi_Square': chi2,\n",
    "                        'P_value': p,\n",
    "                        'Risk_Ratio': risk_ratio,\n",
    "                        'Significant': p < 0.05\n",
    "                    })\n",
    "                    \n",
    "                    # Create visualization (regardless of significance)\n",
    "                    try:\n",
    "                        plt.figure(figsize=(10, 6))\n",
    "                        \n",
    "                        # Calculate percentages\n",
    "                        props = pd.crosstab(\n",
    "                            data[practice_var], \n",
    "                            data[health_var],\n",
    "                            normalize='index'\n",
    "                        ) * 100\n",
    "                        \n",
    "                        # Create bar chart\n",
    "                        ax = props[1].plot(kind='bar')\n",
    "                        \n",
    "                        plt.title(f'{health_var} by {practice_var} (p={p:.4f})', fontsize=14)\n",
    "                        plt.xlabel(practice_var, fontsize=12)\n",
    "                        plt.ylabel(f'Percentage with {health_var}', fontsize=12)\n",
    "                        plt.xticks([0, 1], ['No', 'Yes'])\n",
    "                        plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                        \n",
    "                        # Add percentage labels\n",
    "                        for i, v in enumerate(props[1]):\n",
    "                            ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "                        \n",
    "                        plt.tight_layout()\n",
    "                        \n",
    "                        # Save figure\n",
    "                        fig_path = os.path.join(trad_dir, f\"{practice_var}_vs_{health_var}.png\")\n",
    "                        plt.savefig(fig_path, dpi=300)\n",
    "                        plt.close()\n",
    "                        logger.info(f\"    Saved visualization to {fig_path}\")\n",
    "                        created_visualizations = True\n",
    "                    except Exception as e:\n",
    "                        logger.error(f\"  Error creating visualization: {str(e)}\")\n",
    "                else:\n",
    "                    logger.warning(f\"  Insufficient data for chi-square test for {practice_var} vs {health_var}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"  Error analyzing {practice_var} vs {health_var}: {str(e)}\")\n",
    "        \n",
    "        # Save results\n",
    "        if results:\n",
    "            try:\n",
    "                results_df = pd.DataFrame(results)\n",
    "                results_path = os.path.join(trad_dir, f\"{practice_var}_health_outcomes.csv\")\n",
    "                results_df.to_csv(results_path, index=False)\n",
    "                logger.info(f\"  Saved {practice_var} health outcomes to {results_path}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"  Error saving results: {str(e)}\")\n",
    "    \n",
    "    # Special analysis for respiratory issues with Tabouna smoke if available\n",
    "    if 'exposed_to_tabouna' in available_vars:\n",
    "        logger.info(\"  Performing specific analysis of Tabouna exposure and respiratory issues\")\n",
    "        \n",
    "        # Find respiratory issues variable\n",
    "        resp_vars = [col for col in health_vars if 'respir' in col.lower() or 'cardio' in col.lower()]\n",
    "        \n",
    "        if resp_vars:\n",
    "            resp_var = resp_vars[0]\n",
    "            logger.info(f\"  Using {resp_var} for respiratory analysis\")\n",
    "            \n",
    "            try:\n",
    "                # Create contingency table\n",
    "                contingency = pd.crosstab(data['exposed_to_tabouna'], data[resp_var])\n",
    "                logger.info(f\"  Contingency table for Tabouna vs respiratory issues:\\n{contingency}\")\n",
    "                \n",
    "                # Perform chi-square test\n",
    "                chi2, p, dof, expected = stats.chi2_contingency(contingency)\n",
    "                \n",
    "                # Calculate risk ratio\n",
    "                if 1 in contingency.index and 0 in contingency.index and 1 in contingency.columns:\n",
    "                    risk_exposed = contingency.loc[1, 1] / (contingency.loc[1, 0] + contingency.loc[1, 1])\n",
    "                    risk_unexposed = contingency.loc[0, 1] / (contingency.loc[0, 0] + contingency.loc[0, 1])\n",
    "                    risk_ratio = risk_exposed / risk_unexposed\n",
    "                else:\n",
    "                    risk_exposed = np.nan\n",
    "                    risk_unexposed = np.nan\n",
    "                    risk_ratio = np.nan\n",
    "                \n",
    "                # Create results dataframe\n",
    "                results = pd.DataFrame({\n",
    "                    'Test': ['Tabouna exposure vs. Respiratory issues'],\n",
    "                    'Chi_Square': [chi2],\n",
    "                    'P_value': [p],\n",
    "                    'Risk_Ratio': [risk_ratio],\n",
    "                    'Risk_Exposed': [risk_exposed],\n",
    "                    'Risk_Unexposed': [risk_unexposed],\n",
    "                    'Significant': [p < 0.05]\n",
    "                })\n",
    "                \n",
    "                # Save results\n",
    "                results_path = os.path.join(trad_dir, \"tabouna_respiratory_results.csv\")\n",
    "                results.to_csv(results_path, index=False)\n",
    "                logger.info(f\"    Saved respiratory results to {results_path}\")\n",
    "                \n",
    "                # Create special visualization\n",
    "                plt.figure(figsize=(10, 6))\n",
    "                \n",
    "                # Calculate percentages\n",
    "                props = pd.crosstab(\n",
    "                    data['exposed_to_tabouna'], \n",
    "                    data[resp_var],\n",
    "                    normalize='index'\n",
    "                ) * 100\n",
    "                \n",
    "                # Create bar chart\n",
    "                ax = props[1].plot(kind='bar')\n",
    "                \n",
    "                plt.title(f'Respiratory Issues by Tabouna Exposure (p={p:.4f}, RR={risk_ratio:.2f})', fontsize=14)\n",
    "                plt.xlabel('Exposed to Tabouna Smoke', fontsize=12)\n",
    "                plt.ylabel('Percentage with Respiratory Issues', fontsize=12)\n",
    "                plt.xticks([0, 1], ['No', 'Yes'])\n",
    "                plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "                \n",
    "                # Add percentage labels\n",
    "                for i, v in enumerate(props[1]):\n",
    "                    ax.text(i, v + 1, f'{v:.1f}%', ha='center')\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                \n",
    "                # Save figure\n",
    "                fig_path = os.path.join(trad_dir, \"tabouna_respiratory_issues.png\")\n",
    "                plt.savefig(fig_path, dpi=300)\n",
    "                plt.close()\n",
    "                logger.info(f\"    Saved respiratory visualization to {fig_path}\")\n",
    "                created_visualizations = True\n",
    "            except Exception as e:\n",
    "                logger.error(f\"  Error in respiratory analysis: {str(e)}\")\n",
    "        else:\n",
    "            logger.warning(\"  No respiratory variable found for Tabouna smoke analysis\")\n",
    "    \n",
    "    return created_visualizations\n",
    "\n",
    "def update_summary_report():\n",
    "    \"\"\"Update the summary report with findings from all analyses\"\"\"\n",
    "    logger.info(\"Updating health analysis summary report...\")\n",
    "    \n",
    "    # Create list to store findings\n",
    "    findings = []\n",
    "    \n",
    "    # Helper function to read CSV files and extract findings\n",
    "    def extract_findings_from_csv(file_path, pattern, formatter):\n",
    "        if os.path.exists(file_path):\n",
    "            try:\n",
    "                results = pd.read_csv(file_path)\n",
    "                sig_results = results[results['Significant'] == True] if 'Significant' in results.columns else results\n",
    "                \n",
    "                for _, row in sig_results.iterrows():\n",
    "                    findings.append(formatter(row))\n",
    "                    \n",
    "                return len(sig_results)\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error reading {file_path}: {str(e)}\")\n",
    "                return 0\n",
    "        else:\n",
    "            logger.warning(f\"File not found: {file_path}\")\n",
    "            return 0\n",
    "    \n",
    "    # 1. Check for BMI analysis results\n",
    "    count = extract_findings_from_csv(\n",
    "        os.path.join(output_dir, \"bmi_analysis/bmi_health_chi_square.csv\"),\n",
    "        'Health_Variable',\n",
    "        lambda row: f\"BMI category is significantly associated with {row['Health_Variable']} \" +\n",
    "                    f\"(Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f})\"\n",
    "    )\n",
    "    logger.info(f\"Found {count} significant BMI findings\")\n",
    "    \n",
    "    # 2. Check for blood pressure correlations\n",
    "    count = extract_findings_from_csv(\n",
    "        os.path.join(output_dir, \"blood_pressure/bmi_bp_correlations.csv\"),\n",
    "        'Variable',\n",
    "        lambda row: f\"BMI is significantly correlated with {row['Variable']} \" +\n",
    "                    f\"(r={row['Correlation']:.2f}, p={row['P_value']:.4f})\"\n",
    "    )\n",
    "    logger.info(f\"Found {count} significant blood pressure correlations\")\n",
    "    \n",
    "    # 3. Check for traditional practices results\n",
    "    count = extract_findings_from_csv(\n",
    "        os.path.join(output_dir, \"traditional_practices/tabouna_respiratory_results.csv\"),\n",
    "        'Test',\n",
    "        lambda row: f\"Tabouna smoke exposure is significantly associated with respiratory issues \" +\n",
    "                    f\"(Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f}, \" +\n",
    "                    f\"Risk Ratio={row['Risk_Ratio']:.2f})\"\n",
    "    )\n",
    "    logger.info(f\"Found {count} significant traditional practices findings\")\n",
    "    \n",
    "    # 4. Check for additional traditional practices results\n",
    "    trad_dir = os.path.join(output_dir, \"traditional_practices\")\n",
    "    if os.path.exists(trad_dir):\n",
    "        for file in os.listdir(trad_dir):\n",
    "            if file.endswith(\"_health_outcomes.csv\") and \"tabouna_respiratory_results\" not in file:\n",
    "                count = extract_findings_from_csv(\n",
    "                    os.path.join(trad_dir, file),\n",
    "                    'Health_Outcome',\n",
    "                    lambda row: f\"Traditional practice is significantly associated with {row['Health_Outcome']} \" +\n",
    "                                f\"(Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f}, \" +\n",
    "                                f\"Risk Ratio={row['Risk_Ratio']:.2f if 'Risk_Ratio' in row else 'N/A'})\"\n",
    "                )\n",
    "                logger.info(f\"Found {count} significant findings in {file}\")\n",
    "    \n",
    "    # 5. Check for transportation results\n",
    "    count = extract_findings_from_csv(\n",
    "        os.path.join(output_dir, \"transportation/walking_health_results.csv\"),\n",
    "        'Health_Outcome',\n",
    "        lambda row: f\"Walking as transportation is significantly associated with {row['Health_Outcome']} \" +\n",
    "                    f\"(Chi-square={row['Chi_Square']:.2f}, p={row['P_value']:.4f}, \" +\n",
    "                    f\"Risk Ratio={row['Risk_Ratio']:.2f if 'Risk_Ratio' in row else 'N/A'})\"\n",
    "    )\n",
    "    logger.info(f\"Found {count} significant transportation findings\")\n",
    "    \n",
    "    # Create updated summary report\n",
    "    try:\n",
    "        with open(os.path.join(output_dir, \"health_analysis_summary.txt\"), 'w') as f:\n",
    "            f.write(\"# Health Analysis Summary Report\\n\\n\")\n",
    "            f.write(f\"Date: {pd.Timestamp.now().strftime('%Y-%m-%d')}\\n\")\n",
    "            f.write(f\"Dataset: Female Farmers Health Study\\n\")\n",
    "            f.write(f\"Sample Size: 80\\n\\n\")\n",
    "            \n",
    "            f.write(\"## Key Findings\\n\\n\")\n",
    "            \n",
    "            if findings:\n",
    "                for i, finding in enumerate(findings, 1):\n",
    "                    f.write(f\"{i}. {finding}\\n\")\n",
    "            else:\n",
    "                f.write(\"No significant health relationships were identified. This might be due to the small sample size or data quality issues.\\n\")\n",
    "            \n",
    "            f.write(\"\\n## Analysis Methods\\n\\n\")\n",
    "            f.write(\"The following health analyses were performed:\\n\")\n",
    "            f.write(\"- Relationships between BMI and health outcomes\\n\")\n",
    "            f.write(\"- Blood pressure analysis and its determinants\\n\")\n",
    "            f.write(\"- Impact of traditional practices (Tabouna smoke, Neffa) on health\\n\")\n",
    "            f.write(\"- Work patterns and health relationships\\n\")\n",
    "            f.write(\"- Transportation method and health outcomes\\n\")\n",
    "            f.write(\"- Agricultural experience and health metrics\\n\")\n",
    "            \n",
    "            f.write(\"\\n## Data Limitations\\n\\n\")\n",
    "            f.write(\"- Small sample size limiting statistical power\\n\")\n",
    "            f.write(\"- Missing values in some key variables\\n\")\n",
    "            f.write(\"- Self-reported health complaints may be subject to recall bias\\n\")\n",
    "            \n",
    "            logger.info(\"Summary report updated successfully\")\n",
    "            return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Error updating summary report: {str(e)}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to fix transportation and traditional practices analyses\"\"\"\n",
    "    try:\n",
    "        # Load data\n",
    "        data = load_data()\n",
    "        \n",
    "        # Debug data\n",
    "        debug_data(data)\n",
    "        \n",
    "        # Prepare data for analysis with enhanced checks\n",
    "        analysis_data = prepare_data_for_analysis(data)\n",
    "        \n",
    "        # Run transportation analysis with enhanced diagnostics\n",
    "        logger.info(\"Running transportation health analysis with enhanced diagnostics...\")\n",
    "        trans_success = transportation_health_analysis(analysis_data)\n",
    "        logger.info(f\"Transportation analysis {'completed successfully' if trans_success else 'failed'}\")\n",
    "        \n",
    "        # Run traditional practices analysis with enhanced diagnostics\n",
    "        logger.info(\"Running traditional practices analysis with enhanced diagnostics...\")\n",
    "        trad_success = traditional_practices_analysis(analysis_data)\n",
    "        logger.info(f\"Traditional practices analysis {'completed successfully' if trad_success else 'failed'}\")\n",
    "        \n",
    "        # Update summary report\n",
    "        logger.info(\"Updating summary report...\")\n",
    "        update_summary_report()\n",
    "        \n",
    "        logger.info(\"Analysis fixes completed\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Unexpected error in analysis: {str(e)}\")\n",
    "        logger.exception(\"Detailed error information:\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
